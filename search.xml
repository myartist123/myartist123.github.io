<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ResNet网络</title>
      <link href="/2024/05/20/ResNet%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/05/20/ResNet%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="ResNet网络"><a href="#ResNet网络" class="headerlink" title="ResNet网络"></a>ResNet网络</h1><p><strong>Residual Network，残差网络</strong></p><p>​ResNet 的核心思想是引入了<strong>残差连接</strong>，这允许网络跳过某些层的直接连接，将输入直接添加到网络的后续层输出。这样做的目的是让网络可以<strong>学习到残差函数</strong>（residual function），即输入与输出之间的差异，而不是直接学习映射关系。残差连接有助于<strong>减轻梯度消失</strong>的问题，并允许有效地训练非常深的网络。</p><p>​ResNet 中的基本模块是残差块，它由<strong>两个卷积层和一个跳跃连接</strong>组成。残差块通过残差连接将输入添加到输出中，允许梯度直接通过跳跃连接进行<strong>反向传播</strong>，从而有效地解决了梯度消失的问题。常见的残差块包括基本的残差块和瓶颈残差块。</p><p><img src="/../img/image-20240513114103271.png"></p><blockquote><h2 id="f-x-x-g-x"><a href="#f-x-x-g-x" class="headerlink" title="f(x) &#x3D; x + g(x)"></a><strong>f(x) &#x3D; x + g(x)</strong></h2></blockquote><p>​x表示输入，<strong>𝑔(𝑥)<strong>表示残差块的</strong>学习部分</strong>。这个公式的含义是将输入 𝑥 与学习到的残差 𝑔(𝑥) 相加，得到残差块的输出。让网络学习如何<strong>调整输入 𝑥</strong>，使得 𝑓(𝑥)接近于期望的输出。</p><p>​𝑔(𝑥) 是残差的学习部分，通过卷积层、批量归一化等操作，学习到输入 𝑥 与期望输出之间的<strong>差异</strong>。而 𝑥则表示输入的原始特征。将 𝑥与 𝑔(𝑥)相加可以认为是对 𝑥 进行一个”修正”。</p><p>​这样直接加保证了最优解“<strong>至少不会变差</strong>”，g(x)&#x3D;0是和以前一样的。假设没有学到任何东西，则g(x)为0</p><p><img src="/../img/image-20240513115207311.png"></p><p>​在部分残差块中，为了<strong>减少特征图的维度</strong>，会采用将特征图高度和宽度减半的方式，通常通过步长为 2 的卷积操作(<strong>strides&#x3D;2</strong>)来实现。这会导致 g(x) 的高度和宽度减半。</p><p>​因此，为方便**x + g(x)**，在跳跃连接中加入一个卷积层（1x1 conv），设置strides&#x3D;2，也把x高宽减半了。</p><p><img src="/../img/image-20240513115635901.png"></p><p><img src="/../img/image-20240513115810832.png"></p><h2 id="基于-ResNet-的调制方式识别"><a href="#基于-ResNet-的调制方式识别" class="headerlink" title="基于 ResNet 的调制方式识别"></a>基于 ResNet 的调制方式识别</h2><ol><li><strong>数据集内容</strong>：<ul><li>数据集包含数字调制信号和模拟调制信号。</li><li>信号以 IQ（In-phase and Quadrature）数据格式存储，每个样本有 2 × 128 的形状。</li><li>总共有 220,000 个样本（22万）。</li></ul></li><li><strong>数据生成方式</strong>：<ul><li>使用 Gnuradio 结合 Python 生成数据。</li></ul></li><li><strong>调制方式</strong>：<ul><li>包括 8 种数字调制方式：8PSK、BPSK、CPFSK、GFSK、PAM4、16QAM、64QAM、QPSK。</li><li>还包括 3 种模拟调制方式：AM-DSB、AM-SSB、WBFM。</li></ul></li><li><strong>信噪比范围</strong>：<ul><li>信噪比范围为 -20dB 到 18dB，以 2dB 为间隔。</li></ul></li><li><strong>采样率和频率偏移</strong>：<ul><li>采样率为 200kHz。</li><li>最大采样率偏移为 50Hz。</li><li>最大载波频率偏移为 500Hz。</li></ul></li><li><strong>频率选择性衰落</strong>：<ul><li>使用了 8 个正弦波来模拟频率选择性衰落。</li></ul></li><li><strong>噪声和信道环境</strong>：<ul><li>信道环境包括加性高斯白噪声、选择性衰落（莱斯和瑞利）、中心频率偏移和采样率偏移。</li></ul></li><li><strong>延迟设置</strong>：<ul><li>有 3 个不同的延迟设置，分别为 [0.0, 0.9, 1.7]。</li><li>对应每个延迟时间的幅度分别为 [1, 0.8, 0.3]。</li></ul></li><li><strong>每个样本的形状</strong>：<ul><li>每种调制方式，每种信噪比的数据形状为 (1000, 2, 128)。</li><li>每个样本组数据形状为（1000个样本，每个样本有2个维度，每个维度有128个数据点）。</li></ul></li><li><strong>数据集的特点</strong>：</li></ol><ul><li><p>每个样本包含了不同调制方式在不同信噪比下的信号数据，这样的数据集可以用于训练和测试调制识别算法。</p></li><li><p>数据集提供了丰富的信道环境模拟，有助于研究数字信号在不同干扰条件下的性能表现。</p><h2 id="脚本代码实现："><a href="#脚本代码实现：" class="headerlink" title="脚本代码实现："></a>脚本代码实现：</h2></li></ul><ol><li><strong>数据预处理脚本</strong> (<code>data_preprocessing.py</code>)<ul><li>用于加载、处理和分割数据，并保存数据集到文件中。</li><li><strong>加载数据集：def load_data(dataset_path):</strong><br>从一个包含调制类型和信噪比的字典数据集中加载数据，并将其重塑为特定格式。返回的数据包含重塑后的数组 <code>X</code>、对应的标签 <code>lbl</code> 以及信噪比和调制类型的列表。这样做可以方便后续的机器学习模型进行训练和测试。</li><li><strong>数据集分割：def split_data</strong>(X, lbl, test_size&#x3D;0.2, val_size&#x3D;0.1, random_state&#x3D;42):<br>通过两次调用 <code>train_test_split</code> 函数，将数据集按照指定比例分割成训练集、验证集和测试集。这样做的目的是为了在模型训练过程中，可以有一个独立的验证集来调整超参数，并且有一个独立的测试集来评估模型的最终性能。通过设置 <code>random_state</code> 参数，保证了数据分割的结果是可复现的。</li><li><strong>保存测试集数据：def save_test_data</strong>(X_test, lbl_test, snrs, mods, test_data_path):<br>将测试集的数据和相关信息（标签、信噪比、调制类型）保存到一个指定的文件中。确保测试数据在需要时可以方便地加载和使用。使用 <code>pickle</code> 模块进行序列化，使得数据可以在保存和加载过程中保持其原始结构和类型。</li><li><strong>主函数</strong>：<br>整合了数据处理的各个步骤，首先加载数据集，然后分割数据集，最后保存测试集数据。通过这种方式，可以确保数据处理的各个步骤按照预期的顺序执行。</li></ul></li><li><strong>模型定义脚本</strong> (<code>model.py</code>)<ul><li>定义模型结构和其他与模型相关的函数。</li><li>定义了一个基于 ResNet34 架构的神经网络模型。在初始化过程中，加载了预训练的 ResNet34 模型，并修改了输入通道数和输出类别数。前向传播方法简单地将输入传递给内部的 ResNet34 模型，并返回输出结果。</li></ul></li><li><strong>训练脚本</strong> (<code>train.py</code>)<ul><li>加载数据、初始化模型、训练模型、保存模型权重以及保存测试数据集。</li><li><strong>定义数据集类：ModulationDataset(data.Dataset):</strong><br>这个类定义了一个自定义的数据集类 <code>ModulationDataset</code>，用于加载调制数据集。通过实现 <code>__len__</code> 和 <code>__getitem__</code> 方法，使得该数据集可以被 PyTorch 的数据加载器使用。在 <code>__getitem__</code> 方法中，将特征数据、调制类型和信噪比组合成一个样本，并根据需要进行数据转换。这个类的设计符合 PyTorch 数据加载器的要求，使得可以方便地对数据进行批量处理和训练。</li><li><strong>数据加载器 def get_dataloaders</strong>(X_train, lbl_train, X_val, lbl_val, X_test, lbl_test, mods, snrs, batch_size&#x3D;128):<br>这个函数根据输入的训练集、验证集和测试集的特征数据和标签数据，以及调制类型和信噪比列表，创建了相应的数据集对象和数据加载器。每个数据加载器都可以用于批量加载数据，并根据需要对数据进行随机打乱。这样设计使得数据在训练、验证和测试过程中可以方便地被加载和使用。</li><li><strong>训练模型def train_model</strong>(model, train_loader, val_loader, criterion, optimizer, num_epochs&#x3D;20, device&#x3D;’cuda’, model_save_path&#x3D;’resnet34_model.pth’):<br>这个函数用于训练神经网络模型，并在训练过程中进行验证，选择最佳模型。通过循环遍历每个训练轮次，并在每个轮次内迭代训练和验证阶段，对模型进行训练和评估。在每个阶段内，都计算并打印损失和准确率，并保存训练过程中的最佳模型。最后返回训练完成的最佳模型。</li><li><strong>主函数</strong>：<br>整个训练流程的主控制中心，负责加载数据、创建模型、设置损失函数和优化器，并调用训练函数进行模型训练。通过调用其他函数，实现了整个训练流程的自动化和模块化</li></ul></li><li><strong>评估和可视化脚本</strong> (<code>evaluate_and_plot.py</code>)<ul><li>加载模型和测试数据，进行模型评估，并生成各种可视化图表。</li><li><strong>定义数据集类：ModulationDataset(data.Dataset):</strong><br>这个类定义了一个自定义的数据集类 <code>ModulationDataset</code>，用于加载调制数据集。通过实现 <code>__len__</code> 和 <code>__getitem__</code> 方法，使得该数据集可以被 PyTorch 的数据加载器使用。在 <code>__getitem__</code> 方法中，将特征数据、调制类型和信噪比组合成一个样本，并根据需要进行数据转换。这个类的设计符合 PyTorch 数据加载器的要求，使得可以方便地对数据进行批量处理和训练。</li><li><strong>加载预先保存的测试集数据：def load_test_data</strong>(test_data_path):<br>加载预先保存的测试集数据，并返回加载的测试集特征数据、标签数据、信噪比列表和调制类型列表。通过使用 <code>pickle</code> 模块进行数据的序列化和反序列化，可以方便地在不同的脚本中保存和加载数据，使得测试数据可以在需要时被轻松地加载和使用。</li><li><strong>评估模型：def evaluate_model</strong>(model, dataloader, device&#x3D;’cuda’):<br>用于评估模型在给定数据集上的性能，包括计算准确率以及保存所有预测、所有标签和所有信噪比。通过迭代数据加载器，将数据传递给模型进行推理，并统计模型的正确预测数，最后计算准确率并返回结果。</li><li><strong>绘制结果图函数：</strong><br>绘制不同信噪比下的平均准确率折线图<br>绘制不同信噪比下的调制方式准确率折线图<br>绘制混淆矩阵</li><li><strong>主函数</strong>：<br>实现了整个模型评估的流程，包括加载保存的模型、评估模型性能、计算平均准确率并绘制相应图像。通过这些步骤，可以全面地了解模型在测试集上的性能表现，并进行可视化分析，从而进一步优化和改进模型。</li></ul></li></ol><p><img src="/../img/image-20240515122934153.png"></p><p><img src="/../img/image-20240515123054363.png"></p><p><img src="/../img/image-20240515123157067.png"></p><p><img src="/../img/image-20240515123241610.png"></p><p><img src="/../img/image-20240515123307616.png"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resnet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet 一些写作格式技巧</title>
      <link href="/2024/05/20/%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7/"/>
      <url>/2024/05/20/%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="一些技巧"><a href="#一些技巧" class="headerlink" title="一些技巧"></a>一些技巧</h1><p><strong>还是计算机</strong></p><p><strong>加粗Ctrl+B</strong><br><em>斜体Ctrl+I</em></p><blockquote><p>这是一个引用，&gt;+内容，多层多+几个&gt;</p></blockquote><p><a href="https://blog.csdn.net/qq_40818172?type=lately">这是小白的主页</a></p><p><a href="https://blog.csdn.net/qq_40818172?type=lately">https://blog.csdn.net/qq_40818172?type=lately</a></p><p><img src="/"></p><p>无序列表，使用<code>*</code>、<code>+</code>、<code>-</code>，再加一个空格作为列表的标记</p><ul><li>hhdbcbjhbhj</li></ul><ol><li>hghjggjh</li><li>jbhjbhjbjh</li></ol><p>分割线爱你：—&#x2F;***</p><hr><hr><p>删除线：~~</p><p><del>长江索道何尝不是出版社</del></p><p>下划线：尾添加<code>&lt;u&gt;文本&lt;/u&gt;</code></p><p>代码块：<code>hbhb</code></p><p>代码段：三个&#96;&#96;&#96;</p><p>表格使用<code>|</code>来分割不同的单元格，使用<code>-</code>来分隔表头和其他行</p><ul><li><code>:-</code>：将表头及单元格内容左对齐</li><li><code>-:</code>：将表头及单元格内容右对齐</li><li><code>:-:</code>：将表头及单元格内容居中</li></ul>]]></content>
      
      
      <categories>
          
          <category> 未分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 格式 </tag>
            
            <tag> 技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet 信号调制识别</title>
      <link href="/2024/05/19/ResNet%20%E9%80%9A%E4%BF%A1%E4%BF%A1%E5%8F%B7%E8%AF%86%E5%88%AB/"/>
      <url>/2024/05/19/ResNet%20%E9%80%9A%E4%BF%A1%E4%BF%A1%E5%8F%B7%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="ResNet-信号调制识别"><a href="#ResNet-信号调制识别" class="headerlink" title="ResNet 信号调制识别"></a>ResNet 信号调制识别</h1><p>&lt;img src&#x3D;”&#x2F;img&#x2F;image-20240513193204914.png” style&#x3D;”zoom:50%;” &#x2F;</p><p><img src="/../img/image-20240513193204914.png"></p><p>数据集：RML2016.10a</p><p><img src="/../img/image-20240513203107410.png"></p><p><img src="/../img/image-20240513203123926.png"></p><p><img src="/../img/image-20240513203151707.png"></p><ol><li><strong>数据预处理和加载</strong>：<ul><li>将数据集分为训练集、验证集和测试集。</li><li>使用DataLoader来加载数据。</li></ul></li><li><strong>定义ResNet34模型</strong>：<ul><li>使用PyTorch的预训练模型，并调整最后一层以适应11种调制方式。</li></ul></li><li><strong>训练模型</strong>：<ul><li>定义训练循环，包括损失函数和优化器。</li><li>实现验证循环以评估模型在验证集上的表现。</li></ul></li><li><strong>评估和可视化结果</strong>：<ul><li>计算不同信噪比下的平均准确率并绘制折线图。</li><li>计算不同信噪比下的调制方式准确率并绘制折线图。</li><li>生成混淆矩阵以展示不同调制方式的分类效果。</li></ul></li></ol><pre><code class="highlight python"><span class="keyword">import</span> os<span class="keyword">import</span> pickle  <span class="comment"># 添加这行来导入pickle模块</span><span class="keyword">import</span> time<span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="keyword">import</span> torch<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn<span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim<span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data<span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, ConfusionMatrixDisplay<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm<span class="keyword">import</span> copy  <span class="comment"># 添加这行来导入copy模块</span><span class="comment"># 数据集路径</span>dataset_path = <span class="string">&#x27;RML2016.10a_dict.pkl&#x27;</span>model_save_path = <span class="string">&#x27;resnet34_model.pth&#x27;</span><span class="comment"># 加载数据集</span><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">dataset_path</span>):    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:        Xd = pickle.load(f, encoding=<span class="string">&#x27;latin1&#x27;</span>)    snrs, mods = <span class="built_in">map</span>(<span class="keyword">lambda</span> j: <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[j], Xd.keys())))), [<span class="number">1</span>, <span class="number">0</span>])    X = []    lbl = []    <span class="keyword">for</span> mod <span class="keyword">in</span> mods:        <span class="keyword">for</span> snr <span class="keyword">in</span> snrs:            X.append(Xd[(mod, snr)])            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Xd[(mod, snr)].shape[<span class="number">0</span>]):                lbl.append((mod, snr))    X = np.vstack(X)    <span class="keyword">return</span> X, lbl, snrs, mods<span class="comment"># 数据集分割</span><span class="keyword">def</span> <span class="title function_">split_data</span>(<span class="params">X, lbl, test_size=<span class="number">0.2</span>, val_size=<span class="number">0.1</span>, random_state=<span class="number">42</span></span>):    n_samples = <span class="built_in">len</span>(lbl)    n_test = <span class="built_in">int</span>(n_samples * test_size)    n_val = <span class="built_in">int</span>(n_samples * val_size)    X_train_val, X_test, lbl_train_val, lbl_test = train_test_split(X, lbl, test_size=n_test, random_state=random_state)    X_train, X_val, lbl_train, lbl_val = train_test_split(X_train_val, lbl_train_val, test_size=n_val, random_state=random_state)    <span class="keyword">return</span> (X_train, lbl_train), (X_val, lbl_val), (X_test, lbl_test)<span class="comment"># 定义数据集类</span><span class="keyword">class</span> <span class="title class_">ModulationDataset</span>(data.Dataset):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, lbl, mods, snrs, transform=<span class="literal">None</span></span>):        self.X = X        self.lbl = lbl        self.mods = mods        self.snrs = snrs        self.transform = transform    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):        <span class="keyword">return</span> <span class="built_in">len</span>(self.lbl)    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):        sample = self.X[idx]        sample = np.expand_dims(sample, axis=<span class="number">1</span>)  <span class="comment"># 增加一个维度</span>        label = self.mods.index(self.lbl[idx][<span class="number">0</span>])        snr = self.snrs.index(self.lbl[idx][<span class="number">1</span>])        <span class="keyword">if</span> self.transform:            sample = self.transform(sample)        <span class="keyword">return</span> sample, label, snr<span class="comment"># 数据加载器</span><span class="keyword">def</span> <span class="title function_">get_dataloaders</span>(<span class="params">X_train, lbl_train, X_val, lbl_val, X_test, lbl_test, mods, snrs, batch_size=<span class="number">128</span></span>):    train_dataset = ModulationDataset(X_train, lbl_train, mods, snrs, transform=torch.tensor)    val_dataset = ModulationDataset(X_val, lbl_val, mods, snrs, transform=torch.tensor)    test_dataset = ModulationDataset(X_test, lbl_test, mods, snrs, transform=torch.tensor)    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)    test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)    <span class="keyword">return</span> train_loader, val_loader, test_loader<span class="comment"># 定义ResNet34模型</span><span class="keyword">class</span> <span class="title class_">ResNet34</span>(nn.Module):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">11</span></span>):        <span class="built_in">super</span>(ResNet34, self).__init__()        self.model = models.resnet34(pretrained=<span class="literal">True</span>)        self.model.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)        self.model.fc = nn.Linear(<span class="number">512</span>, num_classes)    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):        <span class="keyword">return</span> self.model(x)<span class="comment"># 训练模型</span><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, train_loader, val_loader, criterion, optimizer, num_epochs=<span class="number">10</span>, device=<span class="string">&#x27;cuda&#x27;</span>, model_save_path=<span class="string">&#x27;resnet34_model.pth&#x27;</span></span>):    best_model_wts = copy.deepcopy(model.state_dict())    best_acc = <span class="number">0.0</span>    <span class="built_in">print</span>(<span class="string">f&#x27;Training on <span class="subst">&#123;device&#125;</span>&#x27;</span>)    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs - <span class="number">1</span>&#125;</span>&#x27;</span>)        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)        epoch_start = time.time()        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:                model.train()                dataloader = train_loader            <span class="keyword">else</span>:                model.<span class="built_in">eval</span>()                dataloader = val_loader            running_loss = <span class="number">0.0</span>            running_corrects = <span class="number">0</span>            <span class="keyword">for</span> inputs, labels, _ <span class="keyword">in</span> tqdm(dataloader):                inputs = inputs.to(device).<span class="built_in">float</span>()                labels = labels.to(device)                optimizer.zero_grad()                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):                    outputs = model(inputs)                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)                    loss = criterion(outputs, labels)                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:                        loss.backward()                        optimizer.step()                running_loss += loss.item() * inputs.size(<span class="number">0</span>)                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)            epoch_loss = running_loss / <span class="built_in">len</span>(dataloader.dataset)            epoch_acc = running_corrects.double() / <span class="built_in">len</span>(dataloader.dataset)            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;phase&#125;</span> Loss: <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;epoch_acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:                best_acc = epoch_acc                best_model_wts = copy.deepcopy(model.state_dict())        epoch_time = time.time() - epoch_start        <span class="built_in">print</span>(<span class="string">f&#x27;Time for epoch <span class="subst">&#123;epoch&#125;</span>: <span class="subst">&#123;epoch_time:<span class="number">.2</span>f&#125;</span> seconds&#x27;</span>)        torch.save(model.state_dict(), model_save_path)    <span class="built_in">print</span>(<span class="string">f&#x27;Best val Acc: <span class="subst">&#123;best_acc:4f&#125;</span>&#x27;</span>)    model.load_state_dict(best_model_wts)    <span class="keyword">return</span> model<span class="comment"># 评估模型</span><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, dataloader, device=<span class="string">&#x27;cuda&#x27;</span></span>):    model.<span class="built_in">eval</span>()    running_corrects = <span class="number">0</span>    all_preds = []    all_labels = []    all_snrs = []    <span class="built_in">print</span>(<span class="string">f&#x27;Evaluating on <span class="subst">&#123;device&#125;</span>&#x27;</span>)    <span class="keyword">for</span> inputs, labels, snrs <span class="keyword">in</span> tqdm(dataloader):        inputs = inputs.to(device).<span class="built_in">float</span>()        labels = labels.to(device)        <span class="keyword">with</span> torch.set_grad_enabled(<span class="literal">False</span>):            outputs = model(inputs)            _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)        running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)        all_preds.extend(preds.cpu().numpy())        all_labels.extend(labels.cpu().numpy())        all_snrs.extend(snrs.numpy())    acc = running_corrects.double() / <span class="built_in">len</span>(dataloader.dataset)    <span class="keyword">return</span> acc, all_preds, all_labels, all_snrs<span class="comment"># 绘制不同信噪比下的平均准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_avg_accuracy</span>(<span class="params">snrs, accuracies</span>):    plt.figure()    plt.plot(snrs, accuracies)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Average Accuracy vs SNR&#x27;</span>)    plt.grid(<span class="literal">True</span>)    plt.show()<span class="comment"># 绘制不同信噪比下的调制方式准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_mod_accuracy</span>(<span class="params">snrs, mod_accuracies, mods</span>):    <span class="keyword">for</span> i, mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mods):        plt.plot(snrs, mod_accuracies[i], label=mod)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Modulation Accuracy vs SNR&#x27;</span>)    plt.legend()    plt.grid(<span class="literal">True</span>)    plt.show()<span class="comment"># 绘制混淆矩阵</span><span class="keyword">def</span> <span class="title function_">plot_confusion_matrix</span>(<span class="params">y_true, y_pred, mods</span>):    cm = confusion_matrix(y_true, y_pred)    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mods)    disp.plot(cmap=plt.cm.Blues)    plt.show()<span class="comment"># 主函数</span><span class="keyword">def</span> <span class="title function_">main</span>():    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)    X, lbl, snrs, mods = load_data(dataset_path)        (X_train, lbl_train), (X_val, lbl_val), (X_test, lbl_test) = split_data(X, lbl)    train_loader, val_loader, test_loader = get_dataloaders(X_train, lbl_train, X_val, lbl_val, X_test, lbl_test, mods, snrs)    model = ResNet34(num_classes=<span class="built_in">len</span>(mods)).to(device)    criterion = nn.CrossEntropyLoss()    optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)    <span class="keyword">if</span> os.path.exists(model_save_path):        <span class="built_in">print</span>(<span class="string">&quot;Loading saved model...&quot;</span>)        model.load_state_dict(torch.load(model_save_path))    <span class="keyword">else</span>:        model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=<span class="number">10</span>, device=device, model_save_path=model_save_path)    acc, all_preds, all_labels, all_snrs = evaluate_model(model, test_loader, device=device)    <span class="built_in">print</span>(<span class="string">f&#x27;Test Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)    snr_acc = &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> snrs&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        <span class="keyword">if</span> snr <span class="keyword">in</span> snr_acc:            snr_acc[snr].append(label == pred)        <span class="keyword">else</span>:            <span class="built_in">print</span>(<span class="string">f&#x27;Warning: SNR <span class="subst">&#123;snr&#125;</span> not found in snr_acc dictionary.&#x27;</span>)    avg_accuracy = [np.mean(snr_acc[snr]) <span class="keyword">for</span> snr <span class="keyword">in</span> snrs]    plot_avg_accuracy(snrs, avg_accuracy)    mod_snr_acc = &#123;mod: &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> snrs&#125; <span class="keyword">for</span> mod <span class="keyword">in</span> mods&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        mod_snr_acc[mods[label]][snr].append(label == pred)    mod_accuracy = [[np.mean(mod_snr_acc[mod][snr]) <span class="keyword">for</span> snr <span class="keyword">in</span> snrs] <span class="keyword">for</span> mod <span class="keyword">in</span> mods]    plot_mod_accuracy(snrs, mod_accuracy, mods)    plot_confusion_matrix(all_labels, all_preds, mods)<span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:    main()</code></pre><pre><code class="highlight python"><span class="keyword">import</span> os<span class="keyword">import</span> pickle<span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="keyword">import</span> torch<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn<span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data<span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, ConfusionMatrixDisplay<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm<span class="comment"># 数据集路径和模型保存路径</span>dataset_path = <span class="string">&#x27;RML2016.10a_dict.pkl&#x27;</span>model_save_path = <span class="string">&#x27;resnet34_model.pth&#x27;</span><span class="comment"># 加载数据集</span><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">dataset_path</span>):    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:        Xd = pickle.load(f, encoding=<span class="string">&#x27;latin1&#x27;</span>)    snrs, mods = <span class="built_in">map</span>(<span class="keyword">lambda</span> j: <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[j], Xd.keys())))), [<span class="number">1</span>, <span class="number">0</span>])    X = []    lbl = []    <span class="keyword">for</span> mod <span class="keyword">in</span> mods:        <span class="keyword">for</span> snr <span class="keyword">in</span> snrs:            X.append(Xd[(mod, snr)])            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Xd[(mod, snr)].shape[<span class="number">0</span>]):                lbl.append((mod, snr))    X = np.vstack(X)    <span class="keyword">return</span> X, lbl, snrs, mods<span class="comment"># 数据集分割，仅获取测试集</span><span class="keyword">def</span> <span class="title function_">split_data</span>(<span class="params">X, lbl, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span></span>):    _, X_test, _, lbl_test = train_test_split(X, lbl, test_size=test_size, random_state=random_state)    <span class="keyword">return</span> X_test, lbl_test<span class="comment"># 定义数据集类</span><span class="keyword">class</span> <span class="title class_">ModulationDataset</span>(data.Dataset):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, lbl, mods, snrs, transform=<span class="literal">None</span></span>):        self.X = X        self.lbl = lbl        self.mods = mods        self.snrs = snrs        self.transform = transform    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):        <span class="keyword">return</span> <span class="built_in">len</span>(self.lbl)    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):        sample = self.X[idx]        sample = np.expand_dims(sample, axis=<span class="number">1</span>)        label = self.mods.index(self.lbl[idx][<span class="number">0</span>])        snr = self.snrs.index(self.lbl[idx][<span class="number">1</span>])        <span class="keyword">if</span> self.transform:            sample = self.transform(sample)        <span class="keyword">return</span> sample, label, snr<span class="comment"># 数据加载器</span><span class="keyword">def</span> <span class="title function_">get_dataloader</span>(<span class="params">X, lbl, mods, snrs, batch_size=<span class="number">128</span>, shuffle=<span class="literal">False</span></span>):    dataset = ModulationDataset(X, lbl, mods, snrs, transform=torch.tensor)    dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)    <span class="keyword">return</span> dataloader<span class="comment"># 定义ResNet34模型</span><span class="keyword">class</span> <span class="title class_">ResNet34</span>(nn.Module):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">11</span></span>):        <span class="built_in">super</span>(ResNet34, self).__init__()        self.model = models.resnet34(pretrained=<span class="literal">True</span>)        self.model.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)        self.model.fc = nn.Linear(<span class="number">512</span>, num_classes)    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):        <span class="keyword">return</span> self.model(x)<span class="comment"># 评估模型</span><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, dataloader, device=<span class="string">&#x27;cuda&#x27;</span></span>):    model.<span class="built_in">eval</span>()    running_corrects = <span class="number">0</span>    all_preds = []    all_labels = []    all_snrs = []    <span class="built_in">print</span>(<span class="string">f&#x27;Evaluating on <span class="subst">&#123;device&#125;</span>&#x27;</span>)    <span class="keyword">for</span> inputs, labels, snrs <span class="keyword">in</span> tqdm(dataloader):        inputs = inputs.to(device).<span class="built_in">float</span>()        labels = labels.to(device)        <span class="keyword">with</span> torch.set_grad_enabled(<span class="literal">False</span>):            outputs = model(inputs)            _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)        running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)        all_preds.extend(preds.cpu().numpy())        all_labels.extend(labels.cpu().numpy())        all_snrs.extend(snrs.numpy())    acc = running_corrects.double() / <span class="built_in">len</span>(dataloader.dataset)    <span class="keyword">return</span> acc, all_preds, all_labels, all_snrs<span class="comment"># 绘制不同信噪比下的平均准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_avg_accuracy</span>(<span class="params">snrs, accuracies</span>):    plt.figure()    plt.plot(snrs, accuracies)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Average Accuracy vs SNR&#x27;</span>)    plt.grid(<span class="literal">True</span>)    plt.savefig(<span class="string">&#x27;avg_accuracy.png&#x27;</span>)    plt.show()<span class="comment"># 绘制不同信噪比下的调制方式准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_mod_accuracy</span>(<span class="params">snrs, mod_accuracies, mods</span>):    <span class="keyword">for</span> i, mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mods):        plt.plot(snrs, mod_accuracies[i], label=mod)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Modulation Accuracy vs SNR&#x27;</span>)    plt.legend()    plt.grid(<span class="literal">True</span>)    plt.savefig(<span class="string">&#x27;mod_accuracy.png&#x27;</span>)    plt.show()<span class="comment"># 绘制混淆矩阵</span><span class="keyword">def</span> <span class="title function_">plot_confusion_matrix</span>(<span class="params">y_true, y_pred, mods</span>):    cm = confusion_matrix(y_true, y_pred)    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mods)    fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">10</span>))  <span class="comment"># 调整图像大小</span>    disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation=<span class="string">&#x27;vertical&#x27;</span>)  <span class="comment"># 标签竖直显示</span>    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>, fontsize=<span class="number">12</span>)    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>, fontsize=<span class="number">12</span>)    plt.title(<span class="string">&#x27;Confusion Matrix&#x27;</span>, fontsize=<span class="number">14</span>)    plt.savefig(<span class="string">&#x27;confusion_matrix.png&#x27;</span>)    plt.show()<span class="comment"># 主函数</span><span class="keyword">def</span> <span class="title function_">main</span>():    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)    X, lbl, snrs, mods = load_data(dataset_path)    X_test, lbl_test = split_data(X, lbl)    test_loader = get_dataloader(X_test, lbl_test, mods, snrs, shuffle=<span class="literal">False</span>)    model = ResNet34(num_classes=<span class="built_in">len</span>(mods)).to(device)    <span class="keyword">if</span> os.path.exists(model_save_path):        <span class="built_in">print</span>(<span class="string">&quot;Loading saved model...&quot;</span>)        model.load_state_dict(torch.load(model_save_path))    <span class="keyword">else</span>:        <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&#x27;Model file not found at <span class="subst">&#123;model_save_path&#125;</span>. Please train the model first.&#x27;</span>)    acc, all_preds, all_labels, all_snrs = evaluate_model(model, test_loader, device=device)    <span class="built_in">print</span>(<span class="string">f&#x27;Test Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)    snr_acc = &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        snr_acc[snr].append(label == pred)    avg_accuracy = [np.mean(snr_acc[snr]) <span class="keyword">if</span> snr_acc[snr] <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))]    plot_avg_accuracy(snrs, avg_accuracy)    mod_snr_acc = &#123;mod: &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))&#125; <span class="keyword">for</span> mod <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mods))&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        mod_snr_acc[label][snr].append(label == pred)    mod_accuracy = [[np.mean(mod_snr_acc[mod][snr]) <span class="keyword">if</span> mod_snr_acc[mod][snr] <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))] <span class="keyword">for</span> mod <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mods))]    plot_mod_accuracy(snrs, mod_accuracy, mods)    plot_confusion_matrix(all_labels, all_preds, mods)<span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:    main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resnet </tag>
            
            <tag> 调制识别 </tag>
            
            <tag> RML2016.10a </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
