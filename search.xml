<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>ResNet网络</title>
      <link href="/2024/05/20/ResNet%E7%BD%91%E7%BB%9C/"/>
      <url>/2024/05/20/ResNet%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="ResNet网络"><a href="#ResNet网络" class="headerlink" title="ResNet网络"></a>ResNet网络</h1><p><strong>Residual Network，残差网络</strong></p><p>​ResNet 的核心思想是引入了<strong>残差连接</strong>，这允许网络跳过某些层的直接连接，将输入直接添加到网络的后续层输出。这样做的目的是让网络可以<strong>学习到残差函数</strong>（residual function），即输入与输出之间的差异，而不是直接学习映射关系。残差连接有助于<strong>减轻梯度消失</strong>的问题，并允许有效地训练非常深的网络。</p><p>​ResNet 中的基本模块是残差块，它由<strong>两个卷积层和一个跳跃连接</strong>组成。残差块通过残差连接将输入添加到输出中，允许梯度直接通过跳跃连接进行<strong>反向传播</strong>，从而有效地解决了梯度消失的问题。常见的残差块包括基本的残差块和瓶颈残差块。</p><p><img src="/../img/image-20240513114103271.png"></p><blockquote><h2 id="f-x-x-g-x"><a href="#f-x-x-g-x" class="headerlink" title="f(x) &#x3D; x + g(x)"></a><strong>f(x) &#x3D; x + g(x)</strong></h2></blockquote><p>​x表示输入，<strong>𝑔(𝑥)<strong>表示残差块的</strong>学习部分</strong>。这个公式的含义是将输入 𝑥 与学习到的残差 𝑔(𝑥) 相加，得到残差块的输出。让网络学习如何<strong>调整输入 𝑥</strong>，使得 𝑓(𝑥)接近于期望的输出。</p><p>​𝑔(𝑥) 是残差的学习部分，通过卷积层、批量归一化等操作，学习到输入 𝑥 与期望输出之间的<strong>差异</strong>。而 𝑥则表示输入的原始特征。将 𝑥与 𝑔(𝑥)相加可以认为是对 𝑥 进行一个”修正”。</p><p>​这样直接加保证了最优解“<strong>至少不会变差</strong>”，g(x)&#x3D;0是和以前一样的。假设没有学到任何东西，则g(x)为0</p><p><img src="/../img/image-20240513115207311.png"></p><p>​在部分残差块中，为了<strong>减少特征图的维度</strong>，会采用将特征图高度和宽度减半的方式，通常通过步长为 2 的卷积操作(<strong>strides&#x3D;2</strong>)来实现。这会导致 g(x) 的高度和宽度减半。</p><p>​因此，为方便**x + g(x)**，在跳跃连接中加入一个卷积层（1x1 conv），设置strides&#x3D;2，也把x高宽减半了。</p><p><img src="/../img/image-20240513115635901.png"></p><p><img src="/../img/image-20240513115810832.png"></p><h2 id="基于-ResNet-的调制方式识别"><a href="#基于-ResNet-的调制方式识别" class="headerlink" title="基于 ResNet 的调制方式识别"></a>基于 ResNet 的调制方式识别</h2><ol><li><strong>数据集内容</strong>：<ul><li>数据集包含数字调制信号和模拟调制信号。</li><li>信号以 IQ（In-phase and Quadrature）数据格式存储，每个样本有 2 × 128 的形状。</li><li>总共有 220,000 个样本（22万）。</li></ul></li><li><strong>数据生成方式</strong>：<ul><li>使用 Gnuradio 结合 Python 生成数据。</li></ul></li><li><strong>调制方式</strong>：<ul><li>包括 8 种数字调制方式：8PSK、BPSK、CPFSK、GFSK、PAM4、16QAM、64QAM、QPSK。</li><li>还包括 3 种模拟调制方式：AM-DSB、AM-SSB、WBFM。</li></ul></li><li><strong>信噪比范围</strong>：<ul><li>信噪比范围为 -20dB 到 18dB，以 2dB 为间隔。</li></ul></li><li><strong>采样率和频率偏移</strong>：<ul><li>采样率为 200kHz。</li><li>最大采样率偏移为 50Hz。</li><li>最大载波频率偏移为 500Hz。</li></ul></li><li><strong>频率选择性衰落</strong>：<ul><li>使用了 8 个正弦波来模拟频率选择性衰落。</li></ul></li><li><strong>噪声和信道环境</strong>：<ul><li>信道环境包括加性高斯白噪声、选择性衰落（莱斯和瑞利）、中心频率偏移和采样率偏移。</li></ul></li><li><strong>延迟设置</strong>：<ul><li>有 3 个不同的延迟设置，分别为 [0.0, 0.9, 1.7]。</li><li>对应每个延迟时间的幅度分别为 [1, 0.8, 0.3]。</li></ul></li><li><strong>每个样本的形状</strong>：<ul><li>每种调制方式，每种信噪比的数据形状为 (1000, 2, 128)。</li><li>每个样本组数据形状为（1000个样本，每个样本有2个维度，每个维度有128个数据点）。</li></ul></li><li><strong>数据集的特点</strong>：</li></ol><ul><li><p>每个样本包含了不同调制方式在不同信噪比下的信号数据，这样的数据集可以用于训练和测试调制识别算法。</p></li><li><p>数据集提供了丰富的信道环境模拟，有助于研究数字信号在不同干扰条件下的性能表现。</p><h2 id="脚本代码实现："><a href="#脚本代码实现：" class="headerlink" title="脚本代码实现："></a>脚本代码实现：</h2></li></ul><ol><li><strong>数据预处理脚本</strong> (<code>data_preprocessing.py</code>)<ul><li>用于加载、处理和分割数据，并保存数据集到文件中。</li><li><strong>加载数据集：def load_data(dataset_path):</strong><br>从一个包含调制类型和信噪比的字典数据集中加载数据，并将其重塑为特定格式。返回的数据包含重塑后的数组 <code>X</code>、对应的标签 <code>lbl</code> 以及信噪比和调制类型的列表。这样做可以方便后续的机器学习模型进行训练和测试。</li><li><strong>数据集分割：def split_data</strong>(X, lbl, test_size&#x3D;0.2, val_size&#x3D;0.1, random_state&#x3D;42):<br>通过两次调用 <code>train_test_split</code> 函数，将数据集按照指定比例分割成训练集、验证集和测试集。这样做的目的是为了在模型训练过程中，可以有一个独立的验证集来调整超参数，并且有一个独立的测试集来评估模型的最终性能。通过设置 <code>random_state</code> 参数，保证了数据分割的结果是可复现的。</li><li><strong>保存测试集数据：def save_test_data</strong>(X_test, lbl_test, snrs, mods, test_data_path):<br>将测试集的数据和相关信息（标签、信噪比、调制类型）保存到一个指定的文件中。确保测试数据在需要时可以方便地加载和使用。使用 <code>pickle</code> 模块进行序列化，使得数据可以在保存和加载过程中保持其原始结构和类型。</li><li><strong>主函数</strong>：<br>整合了数据处理的各个步骤，首先加载数据集，然后分割数据集，最后保存测试集数据。通过这种方式，可以确保数据处理的各个步骤按照预期的顺序执行。</li></ul></li><li><strong>模型定义脚本</strong> (<code>model.py</code>)<ul><li>定义模型结构和其他与模型相关的函数。</li><li>定义了一个基于 ResNet34 架构的神经网络模型。在初始化过程中，加载了预训练的 ResNet34 模型，并修改了输入通道数和输出类别数。前向传播方法简单地将输入传递给内部的 ResNet34 模型，并返回输出结果。</li></ul></li><li><strong>训练脚本</strong> (<code>train.py</code>)<ul><li>加载数据、初始化模型、训练模型、保存模型权重以及保存测试数据集。</li><li><strong>定义数据集类：ModulationDataset(data.Dataset):</strong><br>这个类定义了一个自定义的数据集类 <code>ModulationDataset</code>，用于加载调制数据集。通过实现 <code>__len__</code> 和 <code>__getitem__</code> 方法，使得该数据集可以被 PyTorch 的数据加载器使用。在 <code>__getitem__</code> 方法中，将特征数据、调制类型和信噪比组合成一个样本，并根据需要进行数据转换。这个类的设计符合 PyTorch 数据加载器的要求，使得可以方便地对数据进行批量处理和训练。</li><li><strong>数据加载器 def get_dataloaders</strong>(X_train, lbl_train, X_val, lbl_val, X_test, lbl_test, mods, snrs, batch_size&#x3D;128):<br>这个函数根据输入的训练集、验证集和测试集的特征数据和标签数据，以及调制类型和信噪比列表，创建了相应的数据集对象和数据加载器。每个数据加载器都可以用于批量加载数据，并根据需要对数据进行随机打乱。这样设计使得数据在训练、验证和测试过程中可以方便地被加载和使用。</li><li><strong>训练模型def train_model</strong>(model, train_loader, val_loader, criterion, optimizer, num_epochs&#x3D;20, device&#x3D;’cuda’, model_save_path&#x3D;’resnet34_model.pth’):<br>这个函数用于训练神经网络模型，并在训练过程中进行验证，选择最佳模型。通过循环遍历每个训练轮次，并在每个轮次内迭代训练和验证阶段，对模型进行训练和评估。在每个阶段内，都计算并打印损失和准确率，并保存训练过程中的最佳模型。最后返回训练完成的最佳模型。</li><li><strong>主函数</strong>：<br>整个训练流程的主控制中心，负责加载数据、创建模型、设置损失函数和优化器，并调用训练函数进行模型训练。通过调用其他函数，实现了整个训练流程的自动化和模块化</li></ul></li><li><strong>评估和可视化脚本</strong> (<code>evaluate_and_plot.py</code>)<ul><li>加载模型和测试数据，进行模型评估，并生成各种可视化图表。</li><li><strong>定义数据集类：ModulationDataset(data.Dataset):</strong><br>这个类定义了一个自定义的数据集类 <code>ModulationDataset</code>，用于加载调制数据集。通过实现 <code>__len__</code> 和 <code>__getitem__</code> 方法，使得该数据集可以被 PyTorch 的数据加载器使用。在 <code>__getitem__</code> 方法中，将特征数据、调制类型和信噪比组合成一个样本，并根据需要进行数据转换。这个类的设计符合 PyTorch 数据加载器的要求，使得可以方便地对数据进行批量处理和训练。</li><li><strong>加载预先保存的测试集数据：def load_test_data</strong>(test_data_path):<br>加载预先保存的测试集数据，并返回加载的测试集特征数据、标签数据、信噪比列表和调制类型列表。通过使用 <code>pickle</code> 模块进行数据的序列化和反序列化，可以方便地在不同的脚本中保存和加载数据，使得测试数据可以在需要时被轻松地加载和使用。</li><li><strong>评估模型：def evaluate_model</strong>(model, dataloader, device&#x3D;’cuda’):<br>用于评估模型在给定数据集上的性能，包括计算准确率以及保存所有预测、所有标签和所有信噪比。通过迭代数据加载器，将数据传递给模型进行推理，并统计模型的正确预测数，最后计算准确率并返回结果。</li><li><strong>绘制结果图函数：</strong><br>绘制不同信噪比下的平均准确率折线图<br>绘制不同信噪比下的调制方式准确率折线图<br>绘制混淆矩阵</li><li><strong>主函数</strong>：<br>实现了整个模型评估的流程，包括加载保存的模型、评估模型性能、计算平均准确率并绘制相应图像。通过这些步骤，可以全面地了解模型在测试集上的性能表现，并进行可视化分析，从而进一步优化和改进模型。</li></ul></li></ol><p><img src="/../img/image-20240515122934153.png"></p><p><img src="/../img/image-20240515123054363.png"></p><p><img src="/../img/image-20240515123157067.png"></p><p><img src="/../img/image-20240515123241610.png"></p><p><img src="/../img/image-20240515123307616.png"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resnet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些写作格式技巧</title>
      <link href="/2024/05/20/%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7/"/>
      <url>/2024/05/20/%E4%B8%80%E4%BA%9B%E6%8A%80%E5%B7%A7/</url>
      
        <content type="html"><![CDATA[<h1 id="一些技巧"><a href="#一些技巧" class="headerlink" title="一些技巧"></a>一些技巧</h1><p><strong>还是计算机</strong></p><p><strong>加粗Ctrl+B</strong><br><em>斜体Ctrl+I</em></p><blockquote><p>这是一个引用，&gt;+内容，多层多+几个&gt;</p></blockquote><p><a href="https://blog.csdn.net/qq_40818172?type=lately">这是小白的主页</a></p><p><a href="https://blog.csdn.net/qq_40818172?type=lately">https://blog.csdn.net/qq_40818172?type=lately</a></p><p><img src="/"></p><p>无序列表，使用<code>*</code>、<code>+</code>、<code>-</code>，再加一个空格作为列表的标记</p><ul><li>hhdbcbjhbhj</li></ul><ol><li>hghjggjh</li><li>jbhjbhjbjh</li></ol><p>分割线爱你：—&#x2F;***</p><hr><hr><p>删除线：~~</p><p><del>长江索道何尝不是出版社</del></p><p>下划线：尾添加<code>&lt;u&gt;文本&lt;/u&gt;</code></p><p>代码块：<code>hbhb</code></p><p>代码段：三个&#96;&#96;&#96;</p><p>表格使用<code>|</code>来分割不同的单元格，使用<code>-</code>来分隔表头和其他行</p><ul><li><code>:-</code>：将表头及单元格内容左对齐</li><li><code>-:</code>：将表头及单元格内容右对齐</li><li><code>:-:</code>：将表头及单元格内容居中</li></ul>]]></content>
      
      
      <categories>
          
          <category> 未分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 格式 </tag>
            
            <tag> 技巧 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ResNet 信号调制识别</title>
      <link href="/2024/05/19/ResNet%20%E9%80%9A%E4%BF%A1%E4%BF%A1%E5%8F%B7%E8%AF%86%E5%88%AB/"/>
      <url>/2024/05/19/ResNet%20%E9%80%9A%E4%BF%A1%E4%BF%A1%E5%8F%B7%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="ResNet-信号调制识别"><a href="#ResNet-信号调制识别" class="headerlink" title="ResNet 信号调制识别"></a>ResNet 信号调制识别</h1><p>&lt;img src&#x3D;”&#x2F;img&#x2F;image-20240513193204914.png” style&#x3D;”zoom:50%;” &#x2F;</p><p><img src="/../img/image-20240513193204914.png"></p><p>数据集：RML2016.10a</p><p><img src="/../img/image-20240513203107410.png"></p><p><img src="/../img/image-20240513203123926.png"></p><p><img src="/../img/image-20240513203151707.png"></p><ol><li><strong>数据预处理和加载</strong>：<ul><li>将数据集分为训练集、验证集和测试集。</li><li>使用DataLoader来加载数据。</li></ul></li><li><strong>定义ResNet34模型</strong>：<ul><li>使用PyTorch的预训练模型，并调整最后一层以适应11种调制方式。</li></ul></li><li><strong>训练模型</strong>：<ul><li>定义训练循环，包括损失函数和优化器。</li><li>实现验证循环以评估模型在验证集上的表现。</li></ul></li><li><strong>评估和可视化结果</strong>：<ul><li>计算不同信噪比下的平均准确率并绘制折线图。</li><li>计算不同信噪比下的调制方式准确率并绘制折线图。</li><li>生成混淆矩阵以展示不同调制方式的分类效果。</li></ul></li></ol><pre><code class="highlight python"><span class="keyword">import</span> os<span class="keyword">import</span> pickle  <span class="comment"># 添加这行来导入pickle模块</span><span class="keyword">import</span> time<span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="keyword">import</span> torch<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn<span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim<span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data<span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, ConfusionMatrixDisplay<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm<span class="keyword">import</span> copy  <span class="comment"># 添加这行来导入copy模块</span><span class="comment"># 数据集路径</span>dataset_path = <span class="string">&#x27;RML2016.10a_dict.pkl&#x27;</span>model_save_path = <span class="string">&#x27;resnet34_model.pth&#x27;</span><span class="comment"># 加载数据集</span><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">dataset_path</span>):    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:        Xd = pickle.load(f, encoding=<span class="string">&#x27;latin1&#x27;</span>)    snrs, mods = <span class="built_in">map</span>(<span class="keyword">lambda</span> j: <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[j], Xd.keys())))), [<span class="number">1</span>, <span class="number">0</span>])    X = []    lbl = []    <span class="keyword">for</span> mod <span class="keyword">in</span> mods:        <span class="keyword">for</span> snr <span class="keyword">in</span> snrs:            X.append(Xd[(mod, snr)])            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Xd[(mod, snr)].shape[<span class="number">0</span>]):                lbl.append((mod, snr))    X = np.vstack(X)    <span class="keyword">return</span> X, lbl, snrs, mods<span class="comment"># 数据集分割</span><span class="keyword">def</span> <span class="title function_">split_data</span>(<span class="params">X, lbl, test_size=<span class="number">0.2</span>, val_size=<span class="number">0.1</span>, random_state=<span class="number">42</span></span>):    n_samples = <span class="built_in">len</span>(lbl)    n_test = <span class="built_in">int</span>(n_samples * test_size)    n_val = <span class="built_in">int</span>(n_samples * val_size)    X_train_val, X_test, lbl_train_val, lbl_test = train_test_split(X, lbl, test_size=n_test, random_state=random_state)    X_train, X_val, lbl_train, lbl_val = train_test_split(X_train_val, lbl_train_val, test_size=n_val, random_state=random_state)    <span class="keyword">return</span> (X_train, lbl_train), (X_val, lbl_val), (X_test, lbl_test)<span class="comment"># 定义数据集类</span><span class="keyword">class</span> <span class="title class_">ModulationDataset</span>(data.Dataset):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, lbl, mods, snrs, transform=<span class="literal">None</span></span>):        self.X = X        self.lbl = lbl        self.mods = mods        self.snrs = snrs        self.transform = transform    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):        <span class="keyword">return</span> <span class="built_in">len</span>(self.lbl)    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):        sample = self.X[idx]        sample = np.expand_dims(sample, axis=<span class="number">1</span>)  <span class="comment"># 增加一个维度</span>        label = self.mods.index(self.lbl[idx][<span class="number">0</span>])        snr = self.snrs.index(self.lbl[idx][<span class="number">1</span>])        <span class="keyword">if</span> self.transform:            sample = self.transform(sample)        <span class="keyword">return</span> sample, label, snr<span class="comment"># 数据加载器</span><span class="keyword">def</span> <span class="title function_">get_dataloaders</span>(<span class="params">X_train, lbl_train, X_val, lbl_val, X_test, lbl_test, mods, snrs, batch_size=<span class="number">128</span></span>):    train_dataset = ModulationDataset(X_train, lbl_train, mods, snrs, transform=torch.tensor)    val_dataset = ModulationDataset(X_val, lbl_val, mods, snrs, transform=torch.tensor)    test_dataset = ModulationDataset(X_test, lbl_test, mods, snrs, transform=torch.tensor)    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)    test_loader = data.DataLoader(test_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)    <span class="keyword">return</span> train_loader, val_loader, test_loader<span class="comment"># 定义ResNet34模型</span><span class="keyword">class</span> <span class="title class_">ResNet34</span>(nn.Module):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">11</span></span>):        <span class="built_in">super</span>(ResNet34, self).__init__()        self.model = models.resnet34(pretrained=<span class="literal">True</span>)        self.model.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)        self.model.fc = nn.Linear(<span class="number">512</span>, num_classes)    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):        <span class="keyword">return</span> self.model(x)<span class="comment"># 训练模型</span><span class="keyword">def</span> <span class="title function_">train_model</span>(<span class="params">model, train_loader, val_loader, criterion, optimizer, num_epochs=<span class="number">10</span>, device=<span class="string">&#x27;cuda&#x27;</span>, model_save_path=<span class="string">&#x27;resnet34_model.pth&#x27;</span></span>):    best_model_wts = copy.deepcopy(model.state_dict())    best_acc = <span class="number">0.0</span>    <span class="built_in">print</span>(<span class="string">f&#x27;Training on <span class="subst">&#123;device&#125;</span>&#x27;</span>)    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>/<span class="subst">&#123;num_epochs - <span class="number">1</span>&#125;</span>&#x27;</span>)        <span class="built_in">print</span>(<span class="string">&#x27;-&#x27;</span> * <span class="number">10</span>)        epoch_start = time.time()        <span class="keyword">for</span> phase <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>]:            <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:                model.train()                dataloader = train_loader            <span class="keyword">else</span>:                model.<span class="built_in">eval</span>()                dataloader = val_loader            running_loss = <span class="number">0.0</span>            running_corrects = <span class="number">0</span>            <span class="keyword">for</span> inputs, labels, _ <span class="keyword">in</span> tqdm(dataloader):                inputs = inputs.to(device).<span class="built_in">float</span>()                labels = labels.to(device)                optimizer.zero_grad()                <span class="keyword">with</span> torch.set_grad_enabled(phase == <span class="string">&#x27;train&#x27;</span>):                    outputs = model(inputs)                    _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)                    loss = criterion(outputs, labels)                    <span class="keyword">if</span> phase == <span class="string">&#x27;train&#x27;</span>:                        loss.backward()                        optimizer.step()                running_loss += loss.item() * inputs.size(<span class="number">0</span>)                running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)            epoch_loss = running_loss / <span class="built_in">len</span>(dataloader.dataset)            epoch_acc = running_corrects.double() / <span class="built_in">len</span>(dataloader.dataset)            <span class="built_in">print</span>(<span class="string">f&#x27;<span class="subst">&#123;phase&#125;</span> Loss: <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span> Acc: <span class="subst">&#123;epoch_acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)            <span class="keyword">if</span> phase == <span class="string">&#x27;val&#x27;</span> <span class="keyword">and</span> epoch_acc &gt; best_acc:                best_acc = epoch_acc                best_model_wts = copy.deepcopy(model.state_dict())        epoch_time = time.time() - epoch_start        <span class="built_in">print</span>(<span class="string">f&#x27;Time for epoch <span class="subst">&#123;epoch&#125;</span>: <span class="subst">&#123;epoch_time:<span class="number">.2</span>f&#125;</span> seconds&#x27;</span>)        torch.save(model.state_dict(), model_save_path)    <span class="built_in">print</span>(<span class="string">f&#x27;Best val Acc: <span class="subst">&#123;best_acc:4f&#125;</span>&#x27;</span>)    model.load_state_dict(best_model_wts)    <span class="keyword">return</span> model<span class="comment"># 评估模型</span><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, dataloader, device=<span class="string">&#x27;cuda&#x27;</span></span>):    model.<span class="built_in">eval</span>()    running_corrects = <span class="number">0</span>    all_preds = []    all_labels = []    all_snrs = []    <span class="built_in">print</span>(<span class="string">f&#x27;Evaluating on <span class="subst">&#123;device&#125;</span>&#x27;</span>)    <span class="keyword">for</span> inputs, labels, snrs <span class="keyword">in</span> tqdm(dataloader):        inputs = inputs.to(device).<span class="built_in">float</span>()        labels = labels.to(device)        <span class="keyword">with</span> torch.set_grad_enabled(<span class="literal">False</span>):            outputs = model(inputs)            _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)        running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)        all_preds.extend(preds.cpu().numpy())        all_labels.extend(labels.cpu().numpy())        all_snrs.extend(snrs.numpy())    acc = running_corrects.double() / <span class="built_in">len</span>(dataloader.dataset)    <span class="keyword">return</span> acc, all_preds, all_labels, all_snrs<span class="comment"># 绘制不同信噪比下的平均准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_avg_accuracy</span>(<span class="params">snrs, accuracies</span>):    plt.figure()    plt.plot(snrs, accuracies)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Average Accuracy vs SNR&#x27;</span>)    plt.grid(<span class="literal">True</span>)    plt.show()<span class="comment"># 绘制不同信噪比下的调制方式准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_mod_accuracy</span>(<span class="params">snrs, mod_accuracies, mods</span>):    <span class="keyword">for</span> i, mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mods):        plt.plot(snrs, mod_accuracies[i], label=mod)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Modulation Accuracy vs SNR&#x27;</span>)    plt.legend()    plt.grid(<span class="literal">True</span>)    plt.show()<span class="comment"># 绘制混淆矩阵</span><span class="keyword">def</span> <span class="title function_">plot_confusion_matrix</span>(<span class="params">y_true, y_pred, mods</span>):    cm = confusion_matrix(y_true, y_pred)    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mods)    disp.plot(cmap=plt.cm.Blues)    plt.show()<span class="comment"># 主函数</span><span class="keyword">def</span> <span class="title function_">main</span>():    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)    X, lbl, snrs, mods = load_data(dataset_path)        (X_train, lbl_train), (X_val, lbl_val), (X_test, lbl_test) = split_data(X, lbl)    train_loader, val_loader, test_loader = get_dataloaders(X_train, lbl_train, X_val, lbl_val, X_test, lbl_test, mods, snrs)    model = ResNet34(num_classes=<span class="built_in">len</span>(mods)).to(device)    criterion = nn.CrossEntropyLoss()    optimizer = optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)    <span class="keyword">if</span> os.path.exists(model_save_path):        <span class="built_in">print</span>(<span class="string">&quot;Loading saved model...&quot;</span>)        model.load_state_dict(torch.load(model_save_path))    <span class="keyword">else</span>:        model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=<span class="number">10</span>, device=device, model_save_path=model_save_path)    acc, all_preds, all_labels, all_snrs = evaluate_model(model, test_loader, device=device)    <span class="built_in">print</span>(<span class="string">f&#x27;Test Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)    snr_acc = &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> snrs&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        <span class="keyword">if</span> snr <span class="keyword">in</span> snr_acc:            snr_acc[snr].append(label == pred)        <span class="keyword">else</span>:            <span class="built_in">print</span>(<span class="string">f&#x27;Warning: SNR <span class="subst">&#123;snr&#125;</span> not found in snr_acc dictionary.&#x27;</span>)    avg_accuracy = [np.mean(snr_acc[snr]) <span class="keyword">for</span> snr <span class="keyword">in</span> snrs]    plot_avg_accuracy(snrs, avg_accuracy)    mod_snr_acc = &#123;mod: &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> snrs&#125; <span class="keyword">for</span> mod <span class="keyword">in</span> mods&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        mod_snr_acc[mods[label]][snr].append(label == pred)    mod_accuracy = [[np.mean(mod_snr_acc[mod][snr]) <span class="keyword">for</span> snr <span class="keyword">in</span> snrs] <span class="keyword">for</span> mod <span class="keyword">in</span> mods]    plot_mod_accuracy(snrs, mod_accuracy, mods)    plot_confusion_matrix(all_labels, all_preds, mods)<span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:    main()</code></pre><pre><code class="highlight python"><span class="keyword">import</span> os<span class="keyword">import</span> pickle<span class="keyword">import</span> numpy <span class="keyword">as</span> np<span class="keyword">import</span> torch<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn<span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> data<span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix, ConfusionMatrixDisplay<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split<span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm<span class="comment"># 数据集路径和模型保存路径</span>dataset_path = <span class="string">&#x27;RML2016.10a_dict.pkl&#x27;</span>model_save_path = <span class="string">&#x27;resnet34_model.pth&#x27;</span><span class="comment"># 加载数据集</span><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">dataset_path</span>):    <span class="keyword">with</span> <span class="built_in">open</span>(dataset_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:        Xd = pickle.load(f, encoding=<span class="string">&#x27;latin1&#x27;</span>)    snrs, mods = <span class="built_in">map</span>(<span class="keyword">lambda</span> j: <span class="built_in">sorted</span>(<span class="built_in">list</span>(<span class="built_in">set</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: x[j], Xd.keys())))), [<span class="number">1</span>, <span class="number">0</span>])    X = []    lbl = []    <span class="keyword">for</span> mod <span class="keyword">in</span> mods:        <span class="keyword">for</span> snr <span class="keyword">in</span> snrs:            X.append(Xd[(mod, snr)])            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Xd[(mod, snr)].shape[<span class="number">0</span>]):                lbl.append((mod, snr))    X = np.vstack(X)    <span class="keyword">return</span> X, lbl, snrs, mods<span class="comment"># 数据集分割，仅获取测试集</span><span class="keyword">def</span> <span class="title function_">split_data</span>(<span class="params">X, lbl, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span></span>):    _, X_test, _, lbl_test = train_test_split(X, lbl, test_size=test_size, random_state=random_state)    <span class="keyword">return</span> X_test, lbl_test<span class="comment"># 定义数据集类</span><span class="keyword">class</span> <span class="title class_">ModulationDataset</span>(data.Dataset):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, X, lbl, mods, snrs, transform=<span class="literal">None</span></span>):        self.X = X        self.lbl = lbl        self.mods = mods        self.snrs = snrs        self.transform = transform    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):        <span class="keyword">return</span> <span class="built_in">len</span>(self.lbl)    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):        sample = self.X[idx]        sample = np.expand_dims(sample, axis=<span class="number">1</span>)        label = self.mods.index(self.lbl[idx][<span class="number">0</span>])        snr = self.snrs.index(self.lbl[idx][<span class="number">1</span>])        <span class="keyword">if</span> self.transform:            sample = self.transform(sample)        <span class="keyword">return</span> sample, label, snr<span class="comment"># 数据加载器</span><span class="keyword">def</span> <span class="title function_">get_dataloader</span>(<span class="params">X, lbl, mods, snrs, batch_size=<span class="number">128</span>, shuffle=<span class="literal">False</span></span>):    dataset = ModulationDataset(X, lbl, mods, snrs, transform=torch.tensor)    dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)    <span class="keyword">return</span> dataloader<span class="comment"># 定义ResNet34模型</span><span class="keyword">class</span> <span class="title class_">ResNet34</span>(nn.Module):    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes=<span class="number">11</span></span>):        <span class="built_in">super</span>(ResNet34, self).__init__()        self.model = models.resnet34(pretrained=<span class="literal">True</span>)        self.model.conv1 = nn.Conv2d(<span class="number">2</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)        self.model.fc = nn.Linear(<span class="number">512</span>, num_classes)    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):        <span class="keyword">return</span> self.model(x)<span class="comment"># 评估模型</span><span class="keyword">def</span> <span class="title function_">evaluate_model</span>(<span class="params">model, dataloader, device=<span class="string">&#x27;cuda&#x27;</span></span>):    model.<span class="built_in">eval</span>()    running_corrects = <span class="number">0</span>    all_preds = []    all_labels = []    all_snrs = []    <span class="built_in">print</span>(<span class="string">f&#x27;Evaluating on <span class="subst">&#123;device&#125;</span>&#x27;</span>)    <span class="keyword">for</span> inputs, labels, snrs <span class="keyword">in</span> tqdm(dataloader):        inputs = inputs.to(device).<span class="built_in">float</span>()        labels = labels.to(device)        <span class="keyword">with</span> torch.set_grad_enabled(<span class="literal">False</span>):            outputs = model(inputs)            _, preds = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)        running_corrects += torch.<span class="built_in">sum</span>(preds == labels.data)        all_preds.extend(preds.cpu().numpy())        all_labels.extend(labels.cpu().numpy())        all_snrs.extend(snrs.numpy())    acc = running_corrects.double() / <span class="built_in">len</span>(dataloader.dataset)    <span class="keyword">return</span> acc, all_preds, all_labels, all_snrs<span class="comment"># 绘制不同信噪比下的平均准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_avg_accuracy</span>(<span class="params">snrs, accuracies</span>):    plt.figure()    plt.plot(snrs, accuracies)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Average Accuracy vs SNR&#x27;</span>)    plt.grid(<span class="literal">True</span>)    plt.savefig(<span class="string">&#x27;avg_accuracy.png&#x27;</span>)    plt.show()<span class="comment"># 绘制不同信噪比下的调制方式准确率折线图</span><span class="keyword">def</span> <span class="title function_">plot_mod_accuracy</span>(<span class="params">snrs, mod_accuracies, mods</span>):    <span class="keyword">for</span> i, mod <span class="keyword">in</span> <span class="built_in">enumerate</span>(mods):        plt.plot(snrs, mod_accuracies[i], label=mod)    plt.xlabel(<span class="string">&#x27;SNR (dB)&#x27;</span>)    plt.ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)    plt.title(<span class="string">&#x27;Modulation Accuracy vs SNR&#x27;</span>)    plt.legend()    plt.grid(<span class="literal">True</span>)    plt.savefig(<span class="string">&#x27;mod_accuracy.png&#x27;</span>)    plt.show()<span class="comment"># 绘制混淆矩阵</span><span class="keyword">def</span> <span class="title function_">plot_confusion_matrix</span>(<span class="params">y_true, y_pred, mods</span>):    cm = confusion_matrix(y_true, y_pred)    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=mods)    fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">10</span>))  <span class="comment"># 调整图像大小</span>    disp.plot(cmap=plt.cm.Blues, ax=ax, xticks_rotation=<span class="string">&#x27;vertical&#x27;</span>)  <span class="comment"># 标签竖直显示</span>    plt.xlabel(<span class="string">&#x27;Predicted label&#x27;</span>, fontsize=<span class="number">12</span>)    plt.ylabel(<span class="string">&#x27;True label&#x27;</span>, fontsize=<span class="number">12</span>)    plt.title(<span class="string">&#x27;Confusion Matrix&#x27;</span>, fontsize=<span class="number">14</span>)    plt.savefig(<span class="string">&#x27;confusion_matrix.png&#x27;</span>)    plt.show()<span class="comment"># 主函数</span><span class="keyword">def</span> <span class="title function_">main</span>():    device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)    X, lbl, snrs, mods = load_data(dataset_path)    X_test, lbl_test = split_data(X, lbl)    test_loader = get_dataloader(X_test, lbl_test, mods, snrs, shuffle=<span class="literal">False</span>)    model = ResNet34(num_classes=<span class="built_in">len</span>(mods)).to(device)    <span class="keyword">if</span> os.path.exists(model_save_path):        <span class="built_in">print</span>(<span class="string">&quot;Loading saved model...&quot;</span>)        model.load_state_dict(torch.load(model_save_path))    <span class="keyword">else</span>:        <span class="keyword">raise</span> FileNotFoundError(<span class="string">f&#x27;Model file not found at <span class="subst">&#123;model_save_path&#125;</span>. Please train the model first.&#x27;</span>)    acc, all_preds, all_labels, all_snrs = evaluate_model(model, test_loader, device=device)    <span class="built_in">print</span>(<span class="string">f&#x27;Test Accuracy: <span class="subst">&#123;acc:<span class="number">.4</span>f&#125;</span>&#x27;</span>)    snr_acc = &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        snr_acc[snr].append(label == pred)    avg_accuracy = [np.mean(snr_acc[snr]) <span class="keyword">if</span> snr_acc[snr] <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))]    plot_avg_accuracy(snrs, avg_accuracy)    mod_snr_acc = &#123;mod: &#123;snr: [] <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))&#125; <span class="keyword">for</span> mod <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mods))&#125;    <span class="keyword">for</span> snr, label, pred <span class="keyword">in</span> <span class="built_in">zip</span>(all_snrs, all_labels, all_preds):        mod_snr_acc[label][snr].append(label == pred)    mod_accuracy = [[np.mean(mod_snr_acc[mod][snr]) <span class="keyword">if</span> mod_snr_acc[mod][snr] <span class="keyword">else</span> <span class="number">0</span> <span class="keyword">for</span> snr <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(snrs))] <span class="keyword">for</span> mod <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(mods))]    plot_mod_accuracy(snrs, mod_accuracy, mods)    plot_confusion_matrix(all_labels, all_preds, mods)<span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:    main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> resnet </tag>
            
            <tag> 调制识别 </tag>
            
            <tag> RML2016.10a </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手写数字识别</title>
      <link href="/2024/05/16/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/"/>
      <url>/2024/05/16/%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h1><p>分类问题</p><h2 id="基于keras"><a href="#基于keras" class="headerlink" title="基于keras"></a>基于keras</h2><h2 id="简要过程"><a href="#简要过程" class="headerlink" title="简要过程"></a>简要过程</h2><h3 id="1-下载MINIST数据集"><a href="#1-下载MINIST数据集" class="headerlink" title="1.下载MINIST数据集"></a>1.下载MINIST数据集</h3><p>​直接通过API下载已集成的数据集</p><pre><code class="highlight python"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</code></pre><h3 id="2-数据集可视化"><a href="#2-数据集可视化" class="headerlink" title="2.数据集可视化"></a>2.数据集可视化</h3><p>​单张可视</p><p>​多张可视</p><p>​原始数据可视化</p><p>​应该是用于了解数据集基本情况？</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">mnist_visualize_single</span>(<span class="params">mode, idx</span>):​......<span class="keyword">def</span> <span class="title function_">mnist_visualize_multiple</span>(<span class="params">mode, start, end, length, width</span>):​......<span class="built_in">print</span>(<span class="string">&#x27;训练集图像的尺寸：&#x27;</span>, x_train_original.shape)<span class="built_in">print</span>(<span class="string">&#x27;训练集标签的尺寸：&#x27;</span>, y_train_original.shape)<span class="built_in">print</span>(<span class="string">&#x27;测试集图像的尺寸：&#x27;</span>, x_test_original.shape)<span class="built_in">print</span>(<span class="string">&#x27;测试集标签的尺寸：&#x27;</span>, y_test_original.shape)</code></pre><h3 id="3-数据预处理"><a href="#3-数据预处理" class="headerlink" title="3.数据预处理"></a>3.数据预处理</h3><p>​分配训练集和验证集</p><ol><li>训练集（Train Set）：用于模型的训练。模型在训练集上通过反向传播算法更新参数，以使得模型能够逐渐拟合训练数据的特征和标签。训练集通常包含了大部分的样本数据。</li><li>验证集（Validation Set）：用于模型的调参和评估。在每个训练周期（epoch）结束后，使用验证集评估模型的性能。根据验证集的表现调整模型的超参数，如学习率、正则化参数等。验证集通常用于避免模型在训练过程中过拟合。</li><li>测试集（Test Set）：用于最终评估模型的泛化能力。在模型训练完成后，使用测试集对模型进行最终的性能评估。测试集中的数据是模型之前未见过的，因此测试集评估结果可以反映出模型对于未知数据的泛化能力。测试集的结果通常用于报告模型的最终性能。</li></ol><p>​（样本数，图像高度，图像宽度，通道数）</p><p>​**样本数 (Batch Size)**：表示在一次训练中，我们同时处理的图像数量。</p><p>​**通道数 (Number of Channels)**：表示图像中的颜色通道数或特征通道数。彩色：3个通道：红色、绿色和蓝色（RGB）；灰度图像：1个表示图像的灰度级别</p><p>​图像类型从Uint8转化为float32：数值范围更大</p><p>​归一化</p><pre><code class="highlight python"></code></pre><h3 id="4-构建网络"><a href="#4-构建网络" class="headerlink" title="4.构建网络"></a>4.构建网络</h3><p>​CNN（卷积神经网络）模型做分类</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">CNN_model</span>():​......</code></pre><h3 id="5-编译训练网络"><a href="#5-编译训练网络" class="headerlink" title="5.编译训练网络"></a>5.编译训练网络</h3><p>​直接通过model.compile()编译网络，不用自己写损失函数了？？</p><p>​直接用model.fit()训练网络模型，也不用自己写训练函数了？？</p><p>​写个训练过程可视化函数</p><p>​最后保存训练好的模型</p><pre><code class="highlight python">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])​......train_history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=<span class="number">20</span>, batch_size=<span class="number">32</span>, verbose=<span class="number">2</span>)<span class="keyword">def</span> <span class="title function_">__indef</span> show_train_history(train_history, train, validation):it__(self, num_of_weights):​......model.save(<span class="string">&#x27;handwritten_numeral_recognition.h5&#x27;</span>)</code></pre><h3 id="6-网络预测"><a href="#6-网络预测" class="headerlink" title="6.网络预测"></a>6.网络预测</h3><p>​测试训练好的神经网络在测试集上的情况</p><p>​得到测试精度</p><p>​对测试集进行预测</p><p>​预测结果可视化</p><p>​混淆矩阵：更直观的感知每一种类别的误差</p><pre><code class="highlight python">score = model.evaluate(x_test, y_test)predictions = model.predict(x_test)predictions = np.argmax(predictions, axis=<span class="number">1</span>)<span class="built_in">print</span>(<span class="string">&#x27;前20张图片预测结果：&#x27;</span>, predictions[:<span class="number">20</span>])<span class="keyword">def</span> <span class="title function_">mnist_visualize_multiple_predict</span>(<span class="params">start, end, length, width</span>):    </code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分类问题 </tag>
            
            <tag> keras </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPGA-流水灯</title>
      <link href="/2024/05/12/%E6%B5%81%E6%B0%B4%E7%81%AF/"/>
      <url>/2024/05/12/%E6%B5%81%E6%B0%B4%E7%81%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="FPGA-流水灯"><a href="#FPGA-流水灯" class="headerlink" title="FPGA-流水灯"></a>FPGA-流水灯</h1><h2 id="一、需求分析"><a href="#一、需求分析" class="headerlink" title="一、需求分析"></a>一、需求分析</h2><p>使用开发上的四个LED灯顺序点亮并熄灭，循环往复产生流水灯的效果，流水间隔时间为0.5s</p><h2 id="二、系统设计"><a href="#二、系统设计" class="headerlink" title="二、系统设计"></a>二、系统设计</h2><p>架构设计，包含哪些功能模块，有没有什么设计的瓶颈</p><h2 id="三、硬件选型"><a href="#三、硬件选型" class="headerlink" title="三、硬件选型"></a>三、硬件选型</h2><p>选择与功能相匹配的FPGA芯片</p><h2 id="四、绘制系统框图"><a href="#四、绘制系统框图" class="headerlink" title="四、绘制系统框图"></a>四、绘制系统框图</h2><p>mindmaster软件梳理</p><p>第一步：</p><p><img src="/../img/Snipaste_2024-04-23_21-23-57.png"></p><p>第三步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 221024.png)</p><p>用visio软件，放在doc内</p><p>第二步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-16 195800.png)</p><p>第四步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-16 200706.png)</p><h2 id="五、绘制波形图"><a href="#五、绘制波形图" class="headerlink" title="五、绘制波形图"></a>五、绘制波形图</h2><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-16 203911.png)</p><h2 id="六、编写RTL代码"><a href="#六、编写RTL代码" class="headerlink" title="六、编写RTL代码"></a>六、编写RTL代码</h2><p>用notepad++软件</p><pre><code class="highlight verilog"><span class="keyword">module</span> Timer(    <span class="keyword">input</span> <span class="keyword">wire</span> clk,     <span class="comment">// 时钟信号</span>    <span class="keyword">input</span> <span class="keyword">wire</span> reset,   <span class="comment">// 复位信号</span>    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] time_remaining,  <span class="comment">// 剩余时间信号，4位二进制数表示剩余秒数</span>    <span class="keyword">output</span> <span class="keyword">reg</span> trigger  <span class="comment">// 触发信号，在计时器归零时触发</span>);<span class="comment">// 内部计数器</span><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] counter;<span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">posedge</span> reset) <span class="keyword">begin</span>    <span class="keyword">if</span> (reset) <span class="keyword">begin</span>        <span class="comment">// 在复位信号下，将计数器和剩余时间重置为初始值</span>        counter &lt;= <span class="number">4&#x27;b1111</span>;  <span class="comment">// 15秒</span>        time_remaining &lt;= counter;        trigger &lt;= <span class="number">1&#x27;b0</span>;     <span class="comment">// 触发信号清零</span>    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span>        <span class="comment">// 在时钟信号下，递减计时</span>        <span class="keyword">if</span> (counter &gt; <span class="number">0</span>) <span class="keyword">begin</span>            counter &lt;= counter - <span class="number">1</span>;            time_remaining &lt;= counter;        <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span>            <span class="comment">// 当计时器归零时，触发信号置位</span>            trigger &lt;= <span class="number">1&#x27;b1</span>;        <span class="keyword">end</span>    <span class="keyword">end</span><span class="keyword">end</span><span class="keyword">endmodule</span><span class="keyword">module</span> SevenSegmentDisplay(    <span class="keyword">input</span> <span class="keyword">wire</span> [<span class="number">3</span>:<span class="number">0</span>] number,    <span class="comment">// 输入数字信号，4位二进制数表示</span>    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">6</span>:<span class="number">0</span>] segments   <span class="comment">// 输出数码管分段信号，共阴极</span>);<span class="comment">// 数码管显示表，对应的是共阴极七段数码管的真值表</span><span class="comment">// 顺序为ABCDEFG，1表示点亮，0表示熄灭</span><span class="keyword">reg</span> [<span class="number">6</span>:<span class="number">0</span>] segment_table [<span class="number">0</span>:<span class="number">9</span>] = &#123;    <span class="number">7&#x27;b0000001</span>,  <span class="comment">// 0</span>    <span class="number">7&#x27;b1001111</span>,  <span class="comment">// 1</span>    <span class="number">7&#x27;b0010010</span>,  <span class="comment">// 2</span>    <span class="number">7&#x27;b0000110</span>,  <span class="comment">// 3</span>    <span class="number">7&#x27;b1001100</span>,  <span class="comment">// 4</span>    <span class="number">7&#x27;b0100100</span>,  <span class="comment">// 5</span>    <span class="number">7&#x27;b0100000</span>,  <span class="comment">// 6</span>    <span class="number">7&#x27;b0001111</span>,  <span class="comment">// 7</span>    <span class="number">7&#x27;b0000000</span>,  <span class="comment">// 8 (留空)</span>    <span class="number">7&#x27;b0000100</span>   <span class="comment">// 9</span>&#125;;<span class="comment">// 根据输入数字选择对应的数码管显示表项</span><span class="keyword">always</span> @* <span class="keyword">begin</span>    <span class="keyword">case</span> (number)        <span class="number">4&#x27;b0000</span>: segments = segment_table[<span class="number">0</span>];        <span class="number">4&#x27;b0001</span>: segments = segment_table[<span class="number">1</span>];        <span class="number">4&#x27;b0010</span>: segments = segment_table[<span class="number">2</span>];        <span class="number">4&#x27;b0011</span>: segments = segment_table[<span class="number">3</span>];        <span class="number">4&#x27;b0100</span>: segments = segment_table[<span class="number">4</span>];        <span class="number">4&#x27;b0101</span>: segments = segment_table[<span class="number">5</span>];        <span class="number">4&#x27;b0110</span>: segments = segment_table[<span class="number">6</span>];        <span class="number">4&#x27;b0111</span>: segments = segment_table[<span class="number">7</span>];        <span class="number">4&#x27;b1000</span>: segments = segment_table[<span class="number">8</span>];  <span class="comment">// 显示空白</span>        <span class="number">4&#x27;b1001</span>: segments = segment_table[<span class="number">9</span>];        <span class="keyword">default</span>: segments = <span class="number">7&#x27;b1111111</span>;  <span class="comment">// 默认显示错误</span>    <span class="keyword">endcase</span><span class="keyword">end</span><span class="keyword">endmodule</span><span class="keyword">module</span> ExternalControl(    <span class="keyword">input</span> <span class="keyword">wire</span> reset_switch,      <span class="comment">// 复位控制开关</span>    <span class="keyword">input</span> <span class="keyword">wire</span> start_pause_switch,<span class="comment">// 启动/暂停控制开关</span>    <span class="keyword">output</span> <span class="keyword">reg</span> enable_clock       <span class="comment">// 时钟使能信号</span>);<span class="comment">// 初始状态下，时钟使能信号为0，即计时器停止</span><span class="keyword">assign</span> enable_clock = <span class="number">1&#x27;b0</span>;<span class="comment">// 使用状态机来控制计时器的行为</span><span class="comment">// 状态机包含两个状态：停止和运行</span><span class="comment">// 当启动/暂停控制开关切换时，状态机的状态会相应地改变</span><span class="keyword">reg</span> [<span class="number">1</span>:<span class="number">0</span>] state = <span class="number">2&#x27;b00</span>;<span class="keyword">always</span> @(<span class="keyword">posedge</span> start_pause_switch <span class="keyword">or</span> <span class="keyword">posedge</span> reset_switch) <span class="keyword">begin</span>    <span class="keyword">if</span> (reset_switch) <span class="keyword">begin</span>        <span class="comment">// 复位控制开关被触发时，状态机复位到停止状态</span>        state &lt;= <span class="number">2&#x27;b00</span>;        enable_clock &lt;= <span class="number">1&#x27;b0</span>;    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span>        <span class="comment">// 启动/暂停控制开关被触发时，状态机状态切换</span>        <span class="keyword">case</span> (state)            <span class="number">2&#x27;b00</span>: <span class="keyword">begin</span>                <span class="comment">// 当前状态为停止状态，切换到运行状态</span>                <span class="keyword">if</span> (start_pause_switch) <span class="keyword">begin</span>                    state &lt;= <span class="number">2&#x27;b01</span>;                    enable_clock &lt;= <span class="number">1&#x27;b1</span>; <span class="comment">// 启动计时器</span>                <span class="keyword">end</span>            <span class="keyword">end</span>            <span class="number">2&#x27;b01</span>: <span class="keyword">begin</span>                <span class="comment">// 当前状态为运行状态，切换到停止状态</span>                <span class="keyword">if</span> (start_pause_switch) <span class="keyword">begin</span>                    state &lt;= <span class="number">2&#x27;b00</span>;                    enable_clock &lt;= <span class="number">1&#x27;b0</span>; <span class="comment">// 暂停计时器</span>                <span class="keyword">end</span>            <span class="keyword">end</span>            <span class="keyword">default</span>: state &lt;= <span class="number">2&#x27;b00</span>; <span class="comment">// 默认状态为停止状态</span>        <span class="keyword">endcase</span>    <span class="keyword">end</span><span class="keyword">end</span><span class="keyword">endmodule</span><span class="keyword">module</span> LEDIndicator(    <span class="keyword">input</span> <span class="keyword">wire</span> trigger,  <span class="comment">// 触发信号，计时器归零时触发</span>    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] leds <span class="comment">// LED提示灯信号，4个LED灯</span>);<span class="comment">// 初始状态下，LED提示灯信号为0，即灯处于熄灭状态</span><span class="keyword">assign</span> leds = <span class="number">4&#x27;b0000</span>;<span class="comment">// 当收到触发信号时，点亮LED提示灯</span><span class="keyword">always</span> @(<span class="keyword">posedge</span> trigger) <span class="keyword">begin</span>    leds &lt;= <span class="number">4&#x27;b1111</span>; <span class="comment">// 点亮所有4个LED灯</span><span class="keyword">end</span><span class="keyword">endmodule</span></code></pre><h2 id="七、软件仿真"><a href="#七、软件仿真" class="headerlink" title="七、软件仿真"></a>七、软件仿真</h2><p>编写tb模块代码：在sim文件夹内创建tb文件夹</p><pre><code class="highlight verilog"><span class="meta">`<span class="keyword">timescale</span> 1ns/1ns</span><span class="keyword">module</span> tb_flow_led();<span class="keyword">parameter</span> CLK_PERIOD = <span class="number">20</span>;<span class="keyword">reg</span>           sys_clk;  <span class="comment">//周期20ns</span><span class="keyword">reg</span>           sys_rst_n;<span class="keyword">wire</span>  [<span class="number">3</span>:<span class="number">0</span>]   led;<span class="keyword">initial</span> <span class="keyword">begin</span>    sys_clk &lt;= <span class="number">1&#x27;b0</span>;    sys_rst_n &lt;= <span class="number">1&#x27;b0</span>;    #<span class="number">200</span>    sys_rst_n &lt;= <span class="number">1&#x27;b1</span>;<span class="keyword">end</span><span class="keyword">always</span> <span class="variable">#(CLK_PERIOD/2)</span> sys_clk = ~sys_clk;flow_led u_flow_led(    <span class="variable">.sys_clk</span>       (sys_clk  ),    <span class="variable">.sys_rst_n</span>     (sys_rst_n),    <span class="variable">.led</span>           (led      ));<span class="keyword">endmodule</span></code></pre><p>用modelsim软件仿真</p><p>添加文件并且编译</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110623.png)</p><p>选择tb模块进行编译</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110705.png)</p><p>验证仿真波形</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110821.png)</p><h2 id="八、vivado软件进行后续操作"><a href="#八、vivado软件进行后续操作" class="headerlink" title="八、vivado软件进行后续操作"></a>八、vivado软件进行后续操作</h2><h3 id="1-新建工程"><a href="#1-新建工程" class="headerlink" title="1.新建工程"></a>1.新建工程</h3><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 112745.png)</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 113401.png)</p><h3 id="2-分析与综合"><a href="#2-分析与综合" class="headerlink" title="2.分析与综合"></a>2.分析与综合</h3><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 113616.png)</p><h3 id="3-约束输入"><a href="#3-约束输入" class="headerlink" title="3.约束输入"></a>3.约束输入</h3><p>引脚约束、时序约束</p><p>key和led连接到芯片的哪个引脚？&#x3D;&#x3D;&gt;查看开发板原理图</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 114446.png)</p><p>保存后生成语句：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 114613.png)</p><h3 id="4-设计实现"><a href="#4-设计实现" class="headerlink" title="4.设计实现"></a>4.设计实现</h3><p>一键综合（run synthesis)、布局布线(实现)、生成比特流:Genrate Bitstrem</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 115822.png)</p><p>综合后的设计：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 115621.png)</p><p>看到底层用的器件</p><p>实现后的设计：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 120126.png)</p><h3 id="5-上板验证及调试"><a href="#5-上板验证及调试" class="headerlink" title="5.上板验证及调试"></a>5.上板验证及调试</h3><p>a.连接电源线</p><p>b.电脑&#x3D;&#x3D;&#x3D;下载器&#x3D;&#x3D;&#x3D;板子</p><p>c.拨码开关on，打开电源开关</p><p>d.自动连接</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 120431.png)</p><p>e.自动识别板子型号，下载程序</p><p>f.上板验证</p><p>PS：断电程序丢失</p>]]></content>
      
      
      <categories>
          
          <category> FPGA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> 流水灯 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习入门</title>
      <link href="/2024/05/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/"/>
      <url>/2024/05/10/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="深度学习入门"><a href="#深度学习入门" class="headerlink" title="深度学习入门"></a>深度学习入门</h1><h2 id="一、入门"><a href="#一、入门" class="headerlink" title="一、入门"></a>一、入门</h2><p>使用 NumPy 和 Matplotlib 这两种外部库</p><p>绘制简单图形、显示图像</p><h2 id="二、感知机"><a href="#二、感知机" class="headerlink" title="二、感知机"></a>二、感知机</h2><p><strong>权重和偏置</strong></p><p><strong>单层感知机</strong>：可实现与门、与非门、或门三种逻辑—代码实现</p><p><strong>多层感知机</strong>：可以表示非线性空间，可实现单层感知机无法表示的东西（异或门–2层）</p><h2 id="三、神经网络"><a href="#三、神经网络" class="headerlink" title="三、神经网络"></a>三、神经网络</h2><p>输入层、隐藏层（中间层）、输出层</p><p><strong>激活函数</strong>：决定如何来激活输入信号的总和</p><p>​<strong>感知机</strong>：阶跃函数—-神经元之间流动的是 0 或 1 的二元信号</p><p>​<strong>神经网络</strong>：sigmoid 函数—-连续的实数值信号</p><p>​ReLU（Rectified Linear Unit）函数</p><p>矩阵的点积</p><p><img src="/../img/image-20240513095509081.png"></p><p><strong>三层神经网络的实现</strong>（代码）：直接对权重和偏执初始化（省略学习），然后逐层计算输出y(推理)</p><p>回归问题（输入-预测）用恒等函数，分类问题（输入-归类）用 softmax 函数</p><p><strong>softmax 函数</strong>：</p><p> 0.0 到 1.0 之间的实数，概率</p><p>手写数字识别</p><h2 id="四、神经网络的学习"><a href="#四、神经网络的学习" class="headerlink" title="四、神经网络的学习"></a>四、神经网络的学习</h2><p>训练数据（监督数据）和测试数据</p><p><strong>损失函数</strong>：表示神经网络性能的“恶劣程度”的指标，即当前的 神经网络对监督数据在多大程度上不拟合，在多大程度上不一致。</p><p><strong>均方误差</strong>：</p><p>​mean_squared_error</p><img src="C:\Users\mymdy\Pictures\Screenshots\屏幕截图 2024-04-17 101353.png" alt="第一步" style="zoom:50%;" /><p><strong>交叉熵误差</strong>：</p><p>​cross_entropy_error</p><img src="C:\Users\mymdy\Pictures\Screenshots\屏幕截图 2024-04-17 101449.png" alt="第一步" style="zoom:50%;" /><p><strong>mini-batch 学习</strong>：</p><p>​从训练数据中选出一批数据进行学习</p><p>​np.random.choice(60000, 10)</p><p>​在进行神经网络的学习时，不能将识别精度作为指标。因为如果以 识别精度为指标，则参数的导数在绝大多数地方都会变为 0。</p><p>​sigmoid 函数的导数在任何地方都不为 0</p><p><strong>数值微分</strong>：</p><p>​ numerical_diff(f, x) </p><p>偏导数</p><p><strong>梯度</strong>：</p><p>​全部变量的偏导数汇总而成的向量</p><p>​梯度指示的方向是各点处的函数值减小最多的方向 </p><p><strong>梯度法</strong>：</p><p>​学习时找到最优参数（权重和偏置）（损失函数取最小值时的参数）</p><p>​函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断地沿梯度方向前进。（不断地沿梯度方向前进，逐渐减小函数值的过程）</p><p><strong>学习率</strong>（超参数）：</p><p>​决定在一次学习中 ，应该学习多少 ，以及在多大程度上更新参数 。</p><p>​学习率需要事先确定为某个值，比如 0.01 或 0.001。不能过大过小</p><p><strong>学习算法的实现：</strong></p><p><strong>前提</strong><br>    神经网络存在合适的权重和偏置，调整权重和偏置以便拟合训练数据的<br>过程称为“学习”。神经网络的学习分成下面 4 个步骤。<br><strong>步骤 1（mini-batch）</strong><br>    从训练数据中随机选出一部分数据，这部分数据称为 mini-batch。我们<br>的目标是减小 mini-batch 的损失函数的值。<br><strong>步骤 2（计算梯度）</strong><br>    为了减小 mini-batch 的损失函数的值，需要求出各个权重参数的梯度。<br>梯度表示损失函数的值减小最多的方向。<br><strong>步骤 3（更新参数）</strong><br>    将权重参数沿梯度方向进行微小更新。</p><p><strong>步骤 4（重 复）</strong><br>    重复步骤 1、步骤 2、步骤 3。</p><p>随机梯度下降法（SGD )</p><p>​这个过程可以用一个简单的比喻来解释。想象你是一个探险家，要找到一座隐藏在迷雾中的宝藏。这个迷雾代表着你对问题的不确定性，而宝藏则代表着最优解。你手里拿着一张地图，但是地图不够精确，需要你根据身边的景象不断调整自己的方向。</p><ol><li><strong>步骤 1（mini-batch）</strong>：你无法一次看清整个地图，所以你选择随机挑选一小部分地图来观察。这样做是为了避免过度依赖单个观察而形成偏见。</li><li><strong>步骤 2（计算梯度）</strong>：通过观察当前地图上的特征，比如山脉的轮廓、河流的流向等，你能够推断出应该朝哪个方向走才能更接近宝藏。这就是计算损失函数关于各个权重参数的梯度，它告诉你应该朝哪个方向调整参数才能让损失函数更小。</li><li><strong>步骤 3（更新参数）</strong>：根据梯度的指示，你微调你的方向。如果梯度指向北方，你就朝北走一小步；如果梯度指向南方，你就朝南走一小步。这个过程是逐步地向着更接近宝藏的方向前进，也就是微调权重参数。</li><li><strong>步骤 4（重复）</strong>：重复这个过程，不断观察地图、计算梯度、调整方向，直到你认为自己已经找到了宝藏的位置，或者你走了足够多的步数，认为再往前走也不会更接近宝藏了。</li></ol><p>这个过程就是神经网络学习的核心。通过不断地观察数据、计算梯度、调整参数，神经网络逐渐学习到了如何更好地拟合训练数据，从而完成了任务。</p><h3 id="反向传播："><a href="#反向传播：" class="headerlink" title="反向传播："></a>反向传播：</h3><p><img src="/../img/image-20240513093118588.png"></p><p><img src="/../img/c022b7816770ea48926abfcc4230978.jpg"></p><p><img src="/../img/a6ccfb42604c600c853c1acededdcaa.jpg"></p><p><img src="/../img/c2fee6409c93be072e85f64514857bc.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 感知机 </tag>
            
            <tag> 反向传播 </tag>
            
            <tag> 入门 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Verilog语法</title>
      <link href="/2024/05/08/verilog%E8%AF%AD%E6%B3%95/"/>
      <url>/2024/05/08/verilog%E8%AF%AD%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="Verilog语法"><a href="#Verilog语法" class="headerlink" title="Verilog语法"></a>Verilog语法</h1><h2 id="一、模块"><a href="#一、模块" class="headerlink" title="一、模块"></a>一、模块</h2><pre><code class="highlight verilog"><span class="keyword">module</span> 模块名（口<span class="number">1</span>,口<span class="number">2</span>,口<span class="number">3</span>,......）;</code></pre><p>模块例化方式：</p><pre><code class="highlight verilog"><span class="keyword">module</span> min(<span class="keyword">input</span> clk,<span class="keyword">input</span> rst_n,<span class="keyword">input</span> a1,<span class="keyword">output</span> a2);<span class="keyword">parameter</span>a = <span class="number">1000</span>;<span class="keyword">parameter</span>b =  <span class="number">2000</span>;.....<span class="keyword">endmodule</span></code></pre><pre><code class="highlight verilog">min <span class="variable">#(.a(10),.b(10))</span> uut_min(    <span class="variable">.clk</span>       (clk),    <span class="variable">.rst_n</span>     (rst_n),    <span class="variable">.a1</span>        (a1),    <span class="variable">.a2</span>        (a2)   );<span class="comment">//在模块uut_min中a与b的值就都为10了</span></code></pre><h4 id="模块内容"><a href="#模块内容" class="headerlink" title="模块内容"></a>模块内容</h4><h5 id="I-O说明的格式-输入、输出、输入-输出"><a href="#I-O说明的格式-输入、输出、输入-输出" class="headerlink" title="I&#x2F;O说明的格式: 输入、输出、输入&#x2F;输出"></a>I&#x2F;O说明的格式: 输入、输出、输入&#x2F;输出</h5><pre><code class="highlight verilog"><span class="keyword">input</span>[信号位宽-<span class="number">1</span>:<span class="number">0</span>] 端口名<span class="number">1</span>；<span class="keyword">input</span>[信号位宽-<span class="number">1</span>:<span class="number">0</span>] 端口名<span class="number">2</span>；</code></pre><h5 id="内部信号说明"><a href="#内部信号说明" class="headerlink" title="内部信号说明"></a>内部信号说明</h5><pre><code class="highlight verilog"><span class="keyword">reg</span>[width-<span class="number">1</span>:<span class="number">0</span>] R变量<span class="number">1</span>,R变量<span class="number">2</span>,…;<span class="keyword">wire</span>[width-<span class="number">1</span>:<span class="number">0</span>] W变量<span class="number">1</span>,R变量<span class="number">2</span>,...;<span class="comment">//由always和initial块产生的信号，定义为reg型，其余均定义为wire型；</span></code></pre><h5 id="功能定义"><a href="#功能定义" class="headerlink" title="功能定义"></a>功能定义</h5><pre><code class="highlight verilog"><span class="comment">//用assign连续赋值语句，常用来描述组合逻辑电路；如</span><span class="keyword">assign</span> = a &amp; b<span class="comment">//在“always”模块内被赋值的每一个信号都必须定义成reg型，进行组合逻辑描述时，敏感列表可以直接用@（*）表示，防止敏感事件过多而写掉</span></code></pre><h2 id="二、数据类型、常量、变量"><a href="#二、数据类型、常量、变量" class="headerlink" title="二、数据类型、常量、变量"></a>二、数据类型、常量、变量</h2><p>常用的数据类型:</p><p>reg型、wire型、integer型、parameter型</p><p>x表示不定值，z代表高阻态</p><p>常量：</p><pre><code class="highlight verilog"><span class="keyword">parameter</span> 参数名<span class="number">1</span>=表达式，参数名<span class="number">2</span>=表达式，……参数名n=表达式；</code></pre><p>变量：</p><pre><code class="highlight verilog"><span class="keyword">wire</span> [n-<span class="number">1</span>:<span class="number">0</span>]数据名<span class="number">1</span>，数据名<span class="number">2</span>，……数据名i;<span class="keyword">wire</span>[n:<span class="number">1</span>]数据名<span class="number">1</span>，数据名<span class="number">2</span>，……数据名i;<span class="comment">//wire型数据常用来表示以assign关键字指定的组合逻辑信号，Verilog程序模块中输出信号类型默认定义为wire型。</span></code></pre><h2 id="三、赋值语句和结构说明语句"><a href="#三、赋值语句和结构说明语句" class="headerlink" title="三、赋值语句和结构说明语句"></a>三、赋值语句和结构说明语句</h2><h4 id="非阻塞赋值-“"><a href="#非阻塞赋值-“" class="headerlink" title="非阻塞赋值(“&lt;&#x3D;”)："></a>非阻塞赋值(“&lt;&#x3D;”)：</h4><p>在赋值结束时刻，才更新非阻塞赋值LHS表达式。</p><p>时序逻辑</p><h4 id="阻塞赋值（“-”）："><a href="#阻塞赋值（“-”）：" class="headerlink" title="阻塞赋值（“&#x3D;”）："></a>阻塞赋值（“&#x3D;”）：</h4><p>实时更新</p><p>组合逻辑</p><h4 id="顺序块："><a href="#顺序块：" class="headerlink" title="顺序块："></a>顺序块：</h4><pre><code class="highlight verilog"><span class="keyword">begin</span> ：块名 语句<span class="number">1</span>；语句<span class="number">2</span>；语句n; <span class="keyword">end</span></code></pre><h4 id="并行块"><a href="#并行块" class="headerlink" title="并行块:"></a>并行块:</h4><pre><code class="highlight verilog"><span class="keyword">fork</span>：块名       语句<span class="number">1</span>；              语句<span class="number">2</span>；              语句n；<span class="keyword">join</span></code></pre><h4 id="条件语句："><a href="#条件语句：" class="headerlink" title="条件语句："></a>条件语句：</h4><pre><code class="highlight verilog"><span class="keyword">if</span>（表达式<span class="number">1</span>)  语句<span class="number">1</span>;      <span class="keyword">else</span>  <span class="keyword">if</span>（表达式<span class="number">2</span>）语句<span class="number">2</span>；      <span class="keyword">else</span>  <span class="keyword">if</span>（表达式<span class="number">3</span>）语句<span class="number">3</span>；      ...      <span class="keyword">else</span>  <span class="keyword">if</span>（表达式n）语句n；      <span class="keyword">else</span>   语句n+<span class="number">1</span>；</code></pre><h4 id="case语句"><a href="#case语句" class="headerlink" title="case语句"></a>case语句</h4><h1 id="四、结构语句"><a href="#四、结构语句" class="headerlink" title="四、结构语句"></a>四、结构语句</h1><h3 id="initial语句"><a href="#initial语句" class="headerlink" title="initial语句"></a>initial语句</h3><pre><code class="highlight verilog"><span class="keyword">initial</span>  <span class="keyword">begin</span>语句<span class="number">1</span>；语句<span class="number">2</span>；……语句n;<span class="keyword">end</span></code></pre><h3 id="always语句"><a href="#always语句" class="headerlink" title="always语句"></a>always语句</h3><p>时序行为</p><p><strong>一个程序模块可以有多个initial和always过程块，每个initial和always说明语句在仿真的一开始同时立即开始执行，initial语句只执行一次，而always语句则不断重复活动着，直到仿真过程结束</strong></p><h1 id="五、其他"><a href="#五、其他" class="headerlink" title="五、其他"></a>五、其他</h1><h4 id="时间尺度-timescale"><a href="#时间尺度-timescale" class="headerlink" title="时间尺度&#96;timescale"></a>时间尺度&#96;timescale</h4><pre><code class="highlight verilog"><span class="meta">`<span class="keyword">timescale</span> 10ns/1ns</span><span class="comment">//时间尺度/时间间隔</span><span class="keyword">module</span> test;<span class="keyword">reg</span> set;<span class="keyword">parameter</span> p = <span class="number">1</span><span class="variable">.6</span>;<span class="keyword">initial</span> <span class="keyword">begin</span>$ monitor(<span class="built_in">$time</span>,,<span class="string">&quot;set=&quot;</span>,set);#p set=<span class="number">0</span>;#p set=<span class="number">1</span>;<span class="keyword">end</span><span class="keyword">endmodule</span></code></pre><p>……</p>]]></content>
      
      
      <categories>
          
          <category> FPGA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Verilog </tag>
            
            <tag> 语法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>卷积神经网络（CNN）</title>
      <link href="/2024/05/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89/"/>
      <url>/2024/05/08/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88CNN%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="卷积神经网络（CNN）"><a href="#卷积神经网络（CNN）" class="headerlink" title="卷积神经网络（CNN）"></a>卷积神经网络（CNN）</h1><h2 id="1-整个过程"><a href="#1-整个过程" class="headerlink" title="1.整个过程"></a>1.整个过程</h2><p><img src="/../img/84524c7ae9824d27a871de4ed14038b6.webp"></p><ul><li><p><strong>输入层</strong>：输入图像等信息</p></li><li><p><strong>卷积层（最重要）</strong>：用来提取图像的底层特征</p><p>​先扩充2*（6x6–&gt;8x8）</p><p>​乘上3x3的卷积核（横竖）提取特征，降1*（6x6–&gt;5x5）</p></li><li><p><strong>池化层</strong>：防止过拟合，将数据维度减小</p><p>​拆分成若干个2x2，选取max（2x2），降为1&#x2F;2（6x6–&gt;3x3）</p><p>​过拟合是指机器学习模型在训练数据上表现良好，但在未见过的新数据上表现不佳的情况。</p><p>​过拟合意味着模型对于训练数据中的噪声和细微特征过度敏感，导致了泛化能力下降。</p></li><li><p><strong>全连接层</strong>：汇总卷积层和池化层得到的图像的底层特征和信息</p><p>​扁平化：每一行排成列连接起来作为输入</p></li><li><p><strong>输出层</strong>：根据全连接层的信息得到概率最大的结果</p></li></ul><h2 id="2-输入层"><a href="#2-输入层" class="headerlink" title="2.输入层"></a>2.输入层</h2><p>​就是将图像转换为其对应的由像素值构成的二维矩阵，并将此二维矩阵存储，等待后面几层的操作。</p><h2 id="3-卷积层"><a href="#3-卷积层" class="headerlink" title="3.卷积层"></a>3.卷积层</h2><p>​输入图片二维矩阵</p><p>​确定一个卷积核（二维矩阵）（根据我们想要提取的特征），移动计算得到一个特征图（二维矩阵）</p><p><img src="/../img/8dac00a7d8954ac9930b64dc6e146de6.gif"></p><p>​这样边缘信息会始终比中间信息少计算了，不够公平，所以要拓展一圈，称为padding，当padding&#x3D;1时：</p><p><img src="/../img/7a3fe6889ef640b196a5bb93f9bcaf74.gif"></p><p>​有几个卷积核就有几个特征图</p><p>​一般会多次卷积</p><h2 id="4-池化层"><a href="#4-池化层" class="headerlink" title="4.池化层"></a>4.池化层</h2><p>​通过n个卷积核卷积，得到了n个特征图</p><p>​这些特征图还是太多特征了，会造成1.过拟合，2.维度过高</p><p>​所以要进行池化</p><p>​如何池化？1.最大池化  2.平均池化（向上取整）</p><p><img src="/../img/7feab38ea76349a9bfdc0a3211f4be62.png"></p><p>​池化好处：</p><ul><li>在减少参数量的同时，还保留了原图像的原始特征</li><li>有效防止过拟合</li><li>为卷积神经网络带来平移不变性（原图片特征平移，卷积后可以看出，池化后看不出，也即不变，为后续神经网络的计算带来了方便）</li></ul><p>​一些含义：</p><p>​kernel_size &#x3D; 2：池化&#x2F;卷积过程使用的正方形尺寸是2×2</p><p>​stride &#x3D; 2：每次正方形移动两个位置（从左到右，从上到下）</p><p>​padding &#x3D; 0：没有进行拓展</p><h2 id="5-全连接"><a href="#5-全连接" class="headerlink" title="5.全连接"></a>5.全连接</h2><p>​将池化后的特征图进行展平（平铺层），将其维度变为1 × x的一维向量</p><p>​然后将这个一维向量进行计算，得到每个结果的概率，取最大值</p><p>​这个过程就是一个简单的模型训练过程，通过不断地调整参数值来使识别结果更准确</p><h2 id="6-手写数字识别过程"><a href="#6-手写数字识别过程" class="headerlink" title="6.手写数字识别过程"></a>6.手写数字识别过程</h2><p><img src="/../img/4dd9f14ac3414541a460527f22fbbfe8.png"></p><p>1.将手写数字图片转换为像素矩阵<br>2.对像素矩阵进行Padding不为0的卷积运算，目的是保留边缘特征，生成一个特征图<br>3.对这个特征图使用六个卷积核进行卷积运算，得到六个特征图<br>4.对每个特征图进行池化操作（也可称为下采样操作），在保留特征的同时缩小数据流，生成六个小图，这六个小图和上一层各自的特征图长得很像，但尺寸缩小了<br>5.对池化操作后得到的六个小图进行第二次卷积运算，生成了更多的特征图<br>6.对第二次卷积生成的特征图进行池化操作（下采样操作）<br>7.将第二次池化操作得到的特征进行第一次全连接<br>8.将第一次全连接的结果进行第二次全连接<br>9.将第二次全链接的结果进行最后一次运算，这种运算可能是线性的也可能是非线性的，最终每个位置（一共十个位置，从0到9）都有一个概率值，这个概率值就是将输入的手写数字识别为当前位置数字的概率，最后以概率最大的位置的值作为识别结果。可以看到，右侧上方是我的手写数字，右侧下方是模型（LeNet）的识别结果，最终的识别结果与我输入的手写数字是一致的，这一点从图片左边最上边也可以看到，说明此模型可以成功识别手写数字</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 卷积层 </tag>
            
            <tag> 池化层 </tag>
            
            <tag> 手写识别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPGA-定时器</title>
      <link href="/2024/05/06/FPGA-%E5%AE%9A%E6%97%B6%E5%99%A8/"/>
      <url>/2024/05/06/FPGA-%E5%AE%9A%E6%97%B6%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="FPGA-定时器"><a href="#FPGA-定时器" class="headerlink" title="FPGA-定时器"></a>FPGA-定时器</h1><h2 id="一、需求分析"><a href="#一、需求分析" class="headerlink" title="一、需求分析"></a>一、需求分析</h2><p>1.定时器的时间为15 s，按递减方式进行计时，每隔一秒钟定时器减1；</p><p>2.定时器的时间以数字形式显示在数码管上；</p><p>3.设置两个外部控制开关，控制定时器的直接复位、启动计时，暂停&#x2F;连续计时；</p><p>4.当计时器递减到0时，定时器保持不变，同时发出信号提示灯（4个led灯点亮，表示15s时间已到）</p><h2 id="二、系统设计"><a href="#二、系统设计" class="headerlink" title="二、系统设计"></a>二、系统设计</h2><p>架构设计，包含哪些功能模块，有没有什么设计的瓶颈</p><h2 id="三、硬件选型"><a href="#三、硬件选型" class="headerlink" title="三、硬件选型"></a>三、硬件选型</h2><p>选择与功能相匹配的FPGA芯片</p><p>按键KEY、灯LED原理图</p><p>KEY不按下：1，按下：0</p><p>LED：1–&gt;点亮，0–&gt;熄灭</p><h2 id="四、绘制系统框图"><a href="#四、绘制系统框图" class="headerlink" title="四、绘制系统框图"></a>四、绘制系统框图</h2><p>mindmaster软件梳理</p><p>第一步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 215049.png)</p><p>第四步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 221024.png)</p><p>用visio软件，放在doc内</p><p>第二步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 220124.png)</p><p>第三步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 220821.png)</p><h2 id="五、绘制波形图"><a href="#五、绘制波形图" class="headerlink" title="五、绘制波形图"></a>五、绘制波形图</h2><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 221907.png)</p><h2 id="六、编写RTL代码"><a href="#六、编写RTL代码" class="headerlink" title="六、编写RTL代码"></a>六、编写RTL代码</h2><p>用notepad++软件</p><pre><code class="highlight verilog"><span class="keyword">module</span> Timer(    <span class="keyword">input</span> <span class="keyword">wire</span> clk,     <span class="comment">// 时钟信号</span>    <span class="keyword">input</span> <span class="keyword">wire</span> reset,   <span class="comment">// 复位信号</span>    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] time_remaining,  <span class="comment">// 剩余时间信号，4位二进制数表示剩余秒数</span>    <span class="keyword">output</span> <span class="keyword">reg</span> trigger  <span class="comment">// 触发信号，在计时器归零时触发</span>);<span class="comment">// 内部计数器</span><span class="keyword">reg</span> [<span class="number">3</span>:<span class="number">0</span>] counter;<span class="keyword">always</span> @(<span class="keyword">posedge</span> clk <span class="keyword">or</span> <span class="keyword">posedge</span> reset) <span class="keyword">begin</span>    <span class="keyword">if</span> (reset) <span class="keyword">begin</span>        <span class="comment">// 在复位信号下，将计数器和剩余时间重置为初始值</span>        counter &lt;= <span class="number">4&#x27;b1111</span>;  <span class="comment">// 15秒</span>        time_remaining &lt;= counter;        trigger &lt;= <span class="number">1&#x27;b0</span>;     <span class="comment">// 触发信号清零</span>    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span>        <span class="comment">// 在时钟信号下，递减计时</span>        <span class="keyword">if</span> (counter &gt; <span class="number">0</span>) <span class="keyword">begin</span>            counter &lt;= counter - <span class="number">1</span>;            time_remaining &lt;= counter;        <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span>            <span class="comment">// 当计时器归零时，触发信号置位</span>            trigger &lt;= <span class="number">1&#x27;b1</span>;        <span class="keyword">end</span>    <span class="keyword">end</span><span class="keyword">end</span><span class="keyword">endmodule</span><span class="keyword">module</span> SevenSegmentDisplay(    <span class="keyword">input</span> <span class="keyword">wire</span> [<span class="number">3</span>:<span class="number">0</span>] number,    <span class="comment">// 输入数字信号，4位二进制数表示</span>    <span class="keyword">output</span> <span class="keyword">reg</span> [<span class="number">6</span>:<span class="number">0</span>] segments   <span class="comment">// 输出数码管分段信号，共阴极</span>);<span class="comment">// 数码管显示表，对应的是共阴极七段数码管的真值表</span><span class="comment">// 顺序为ABCDEFG，1表示点亮，0表示熄灭</span><span class="keyword">reg</span> [<span class="number">6</span>:<span class="number">0</span>] segment_table [<span class="number">0</span>:<span class="number">9</span>] = &#123;    <span class="number">7&#x27;b0000001</span>,  <span class="comment">// 0</span>    <span class="number">7&#x27;b1001111</span>,  <span class="comment">// 1</span>    <span class="number">7&#x27;b0010010</span>,  <span class="comment">// 2</span>    <span class="number">7&#x27;b0000110</span>,  <span class="comment">// 3</span>    <span class="number">7&#x27;b1001100</span>,  <span class="comment">// 4</span>    <span class="number">7&#x27;b0100100</span>,  <span class="comment">// 5</span>    <span class="number">7&#x27;b0100000</span>,  <span class="comment">// 6</span>    <span class="number">7&#x27;b0001111</span>,  <span class="comment">// 7</span>    <span class="number">7&#x27;b0000000</span>,  <span class="comment">// 8 (留空)</span>    <span class="number">7&#x27;b0000100</span>   <span class="comment">// 9</span>&#125;;<span class="comment">// 根据输入数字选择对应的数码管显示表项</span><span class="keyword">always</span> @* <span class="keyword">begin</span>    <span class="keyword">case</span> (number)        <span class="number">4&#x27;b0000</span>: segments = segment_table[<span class="number">0</span>];        <span class="number">4&#x27;b0001</span>: segments = segment_table[<span class="number">1</span>];        <span class="number">4&#x27;b0010</span>: segments = segment_table[<span class="number">2</span>];        <span class="number">4&#x27;b0011</span>: segments = segment_table[<span class="number">3</span>];        <span class="number">4&#x27;b0100</span>: segments = segment_table[<span class="number">4</span>];        <span class="number">4&#x27;b0101</span>: segments = segment_table[<span class="number">5</span>];        <span class="number">4&#x27;b0110</span>: segments = segment_table[<span class="number">6</span>];        <span class="number">4&#x27;b0111</span>: segments = segment_table[<span class="number">7</span>];        <span class="number">4&#x27;b1000</span>: segments = segment_table[<span class="number">8</span>];  <span class="comment">// 显示空白</span>        <span class="number">4&#x27;b1001</span>: segments = segment_table[<span class="number">9</span>];        <span class="keyword">default</span>: segments = <span class="number">7&#x27;b1111111</span>;  <span class="comment">// 默认显示错误</span>    <span class="keyword">endcase</span><span class="keyword">end</span><span class="keyword">endmodule</span><span class="keyword">module</span> ExternalControl(    <span class="keyword">input</span> <span class="keyword">wire</span> reset_switch,      <span class="comment">// 复位控制开关</span>    <span class="keyword">input</span> <span class="keyword">wire</span> start_pause_switch,<span class="comment">// 启动/暂停控制开关</span>    <span class="keyword">output</span> <span class="keyword">reg</span> enable_clock       <span class="comment">// 时钟使能信号</span>);<span class="comment">// 初始状态下，时钟使能信号为0，即计时器停止</span><span class="keyword">assign</span> enable_clock = <span class="number">1&#x27;b0</span>;<span class="comment">// 使用状态机来控制计时器的行为</span><span class="comment">// 状态机包含两个状态：停止和运行</span><span class="comment">// 当启动/暂停控制开关切换时，状态机的状态会相应地改变</span><span class="keyword">reg</span> [<span class="number">1</span>:<span class="number">0</span>] state = <span class="number">2&#x27;b00</span>;<span class="keyword">always</span> @(<span class="keyword">negedge</span> start_pause_switch <span class="keyword">or</span> <span class="keyword">posedge</span> reset_switch) <span class="keyword">begin</span>    <span class="keyword">if</span> (reset_switch) <span class="keyword">begin</span>        <span class="comment">// 复位控制开关被触发时，状态机复位到停止状态</span>        state &lt;= <span class="number">2&#x27;b00</span>;        enable_clock &lt;= <span class="number">1&#x27;b0</span>;    <span class="keyword">end</span> <span class="keyword">else</span> <span class="keyword">begin</span>        <span class="comment">// 启动/暂停控制开关被触发时，状态机状态切换</span>        <span class="keyword">case</span> (state)            <span class="number">2&#x27;b00</span>: <span class="keyword">begin</span>                <span class="comment">// 当前状态为停止状态，切换到运行状态</span>                <span class="keyword">if</span> (start_pause_switch) <span class="keyword">begin</span>                    state &lt;= <span class="number">2&#x27;b01</span>;                    enable_clock &lt;= <span class="number">1&#x27;b1</span>; <span class="comment">// 启动计时器</span>                <span class="keyword">end</span>            <span class="keyword">end</span>            <span class="number">2&#x27;b01</span>: <span class="keyword">begin</span>                <span class="comment">// 当前状态为运行状态，切换到停止状态</span>                <span class="keyword">if</span> (start_pause_switch) <span class="keyword">begin</span>                    state &lt;= <span class="number">2&#x27;b00</span>;                    enable_clock &lt;= <span class="number">1&#x27;b0</span>; <span class="comment">// 暂停计时器</span>                <span class="keyword">end</span>            <span class="keyword">end</span>            <span class="keyword">default</span>: state &lt;= <span class="number">2&#x27;b00</span>; <span class="comment">// 默认状态为停止状态</span>        <span class="keyword">endcase</span>    <span class="keyword">end</span><span class="keyword">end</span><span class="keyword">endmodule</span><span class="keyword">module</span> LEDIndicator(    <span class="keyword">input</span> <span class="keyword">wire</span> trigger,  <span class="comment">// 触发信号，计时器归零时触发</span>    <span class="keyword">output</span> <span class="keyword">wire</span> [<span class="number">3</span>:<span class="number">0</span>] leds <span class="comment">// LED提示灯信号，4个LED灯</span>);<span class="comment">// 初始状态下，LED提示灯信号为0，即灯处于熄灭状态</span><span class="keyword">assign</span> leds = <span class="number">4&#x27;b0000</span>;<span class="comment">// 当收到触发信号时，点亮LED提示灯</span><span class="keyword">always</span> @(<span class="keyword">posedge</span> trigger) <span class="keyword">begin</span>    leds &lt;= <span class="number">4&#x27;b1111</span>; <span class="comment">// 点亮所有4个LED灯</span><span class="keyword">end</span><span class="keyword">endmodule</span></code></pre><h2 id="七、软件仿真"><a href="#七、软件仿真" class="headerlink" title="七、软件仿真"></a>七、软件仿真</h2><p>仿真前绘制visio：tb模块（testbench）（测试文件），模拟按键变化</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 102713.png)</p><p>编写tb模块代码：在sim文件夹内创建tb文件夹</p><pre><code class="highlight verilog"><span class="comment">//tb_led.v</span><span class="meta">`<span class="keyword">timescale</span> 1ns/1ns  </span><span class="comment">//单位/精度</span><span class="keyword">module</span> tb_led();<span class="keyword">reg</span>    key;<span class="comment">//在initial语句赋值，所以定义为reg</span><span class="keyword">wire</span>   led;<span class="keyword">initial</span> <span class="keyword">begin</span>     key &lt;=<span class="number">1&#x27;b1</span>;     #<span class="number">200</span>     key &lt;=<span class="number">1&#x27;b0</span>;     #<span class="number">500</span>     key &lt;=<span class="number">1&#x27;b1</span>;     #<span class="number">1000</span>     key &lt;=<span class="number">1&#x27;b0</span>;     #<span class="number">1000</span>     key &lt;=<span class="number">1&#x27;b1</span>;<span class="keyword">end</span><span class="comment">//对LED进行例化</span>led u_led(    <span class="variable">.key</span>     (key),    <span class="variable">.led</span>     (led));<span class="keyword">endmodule</span></code></pre><p>用modelsim软件仿真</p><p>添加文件并且编译</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110623.png)</p><p>选择tb模块进行编译</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110705.png)</p><p>验证仿真波形</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110821.png)</p><h2 id="八、vivado软件进行后续操作"><a href="#八、vivado软件进行后续操作" class="headerlink" title="八、vivado软件进行后续操作"></a>八、vivado软件进行后续操作</h2><h3 id="1-新建工程"><a href="#1-新建工程" class="headerlink" title="1.新建工程"></a>1.新建工程</h3><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 112745.png)</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 113401.png)</p><h3 id="2-分析与综合"><a href="#2-分析与综合" class="headerlink" title="2.分析与综合"></a>2.分析与综合</h3><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 113616.png)</p><h3 id="3-约束输入"><a href="#3-约束输入" class="headerlink" title="3.约束输入"></a>3.约束输入</h3><p>引脚约束、时序约束</p><p>key和led连接到芯片的哪个引脚？&#x3D;&#x3D;&gt;查看开发板原理图</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 114446.png)</p><p>保存后生成语句：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 114613.png)</p><h3 id="4-设计实现"><a href="#4-设计实现" class="headerlink" title="4.设计实现"></a>4.设计实现</h3><p>一键综合（run synthesis)、布局布线(实现)、生成比特流:Genrate Bitstrem</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 115822.png)</p><p>综合后的设计：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 115621.png)</p><p>看到底层用的器件</p><p>实现后的设计：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 120126.png)</p><h3 id="5-上板验证及调试"><a href="#5-上板验证及调试" class="headerlink" title="5.上板验证及调试"></a>5.上板验证及调试</h3><p>a.连接电源线</p><p>b.电脑&#x3D;&#x3D;&#x3D;下载器&#x3D;&#x3D;&#x3D;板子</p><p>c.拨码开关on，打开电源开关</p><p>d.自动连接</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 120431.png)</p><p>e.自动识别板子型号，下载程序</p><p>f.上板验证</p><p>PS：断电程序丢失</p>]]></content>
      
      
      <categories>
          
          <category> FPGA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> 定时器 </tag>
            
            <tag> 流程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPGA开发流程（点亮LED）</title>
      <link href="/2024/05/06/FPGA%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%EF%BC%88%E7%82%B9%E4%BA%AELED%EF%BC%89/"/>
      <url>/2024/05/06/FPGA%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B%EF%BC%88%E7%82%B9%E4%BA%AELED%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h1 id="FPGA开发流程（点亮LED）"><a href="#FPGA开发流程（点亮LED）" class="headerlink" title="FPGA开发流程（点亮LED）"></a>FPGA开发流程（点亮LED）</h1><h2 id="一、需求分析"><a href="#一、需求分析" class="headerlink" title="一、需求分析"></a>一、需求分析</h2><p>KEY没有被按下，LED保持常灭；KEY被按下，LED被点亮。</p><h2 id="二、系统设计"><a href="#二、系统设计" class="headerlink" title="二、系统设计"></a>二、系统设计</h2><p>架构设计，包含哪些功能模块，有没有什么设计的瓶颈</p><h2 id="三、硬件选型"><a href="#三、硬件选型" class="headerlink" title="三、硬件选型"></a>三、硬件选型</h2><p>选择与功能相匹配的FPGA芯片</p><p>按键KEY、灯LED原理图</p><p>KEY不按下：1，按下：0</p><p>LED：1–&gt;点亮，0–&gt;熄灭</p><h2 id="四、绘制系统框图"><a href="#四、绘制系统框图" class="headerlink" title="四、绘制系统框图"></a>四、绘制系统框图</h2><p>mindmaster软件梳理</p><p>第一步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 215049.png)</p><p>第四步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 221024.png)</p><p>用visio软件，放在doc内</p><p>第二步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 220124.png)</p><p>第三步：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 220821.png)</p><h2 id="五、绘制波形图"><a href="#五、绘制波形图" class="headerlink" title="五、绘制波形图"></a>五、绘制波形图</h2><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-02 221907.png)</p><h2 id="六、编写RTL代码"><a href="#六、编写RTL代码" class="headerlink" title="六、编写RTL代码"></a>六、编写RTL代码</h2><p>用notepad++软件</p><pre><code class="highlight verilog"><span class="comment">//led.v</span><span class="keyword">module</span> led(    <span class="keyword">input</span> key,<span class="comment">//输入按键，默认为高电平</span>    <span class="keyword">output</span> led <span class="comment">//输出LED，高电平点亮</span>);<span class="keyword">assign</span> led = ~key;<span class="keyword">endmodule</span></code></pre><h2 id="七、软件仿真"><a href="#七、软件仿真" class="headerlink" title="七、软件仿真"></a>七、软件仿真</h2><p>仿真前绘制visio：tb模块（testbench）（测试文件），模拟按键变化</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 102713.png)</p><p>编写tb模块代码：在sim文件夹内创建tb文件夹</p><pre><code class="highlight verilog"><span class="comment">//tb_led.v</span><span class="meta">`<span class="keyword">timescale</span> 1ns/1ns  </span><span class="comment">//单位/精度</span><span class="keyword">module</span> tb_led();<span class="keyword">reg</span>    key;<span class="comment">//在initial语句赋值，所以定义为reg</span><span class="keyword">wire</span>   led;<span class="keyword">initial</span> <span class="keyword">begin</span>     key &lt;=<span class="number">1&#x27;b1</span>;     #<span class="number">200</span>     key &lt;=<span class="number">1&#x27;b0</span>;     #<span class="number">500</span>     key &lt;=<span class="number">1&#x27;b1</span>;     #<span class="number">1000</span>     key &lt;=<span class="number">1&#x27;b0</span>;     #<span class="number">1000</span>     key &lt;=<span class="number">1&#x27;b1</span>;<span class="keyword">end</span><span class="comment">//对LED进行例化</span>led u_led(    <span class="variable">.key</span>     (key),    <span class="variable">.led</span>     (led));<span class="keyword">endmodule</span></code></pre><p>用modelsim软件仿真</p><p>添加文件并且编译</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110623.png)</p><p>选择tb模块进行编译</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110705.png)</p><p>验证仿真波形</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 110821.png)</p><h2 id="八、vivado软件进行后续操作"><a href="#八、vivado软件进行后续操作" class="headerlink" title="八、vivado软件进行后续操作"></a>八、vivado软件进行后续操作</h2><h3 id="1-新建工程"><a href="#1-新建工程" class="headerlink" title="1.新建工程"></a>1.新建工程</h3><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 112745.png)</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 113401.png)</p><h3 id="2-分析与综合"><a href="#2-分析与综合" class="headerlink" title="2.分析与综合"></a>2.分析与综合</h3><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 113616.png)</p><h3 id="3-约束输入"><a href="#3-约束输入" class="headerlink" title="3.约束输入"></a>3.约束输入</h3><p>引脚约束、时序约束</p><p>key和led连接到芯片的哪个引脚？&#x3D;&#x3D;&gt;查看开发板原理图</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 114446.png)</p><p>保存后生成语句：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 114613.png)</p><h3 id="4-设计实现"><a href="#4-设计实现" class="headerlink" title="4.设计实现"></a>4.设计实现</h3><p>一键综合（run synthesis)、布局布线(实现)、生成比特流:Genrate Bitstrem</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 115822.png)</p><p>综合后的设计：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 115621.png)</p><p>看到底层用的器件</p><p>实现后的设计：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 120126.png)</p><h3 id="5-上板验证及调试"><a href="#5-上板验证及调试" class="headerlink" title="5.上板验证及调试"></a>5.上板验证及调试</h3><p>a.连接电源线</p><p>b.电脑&#x3D;&#x3D;&#x3D;下载器&#x3D;&#x3D;&#x3D;板子</p><p>c.拨码开关on，打开电源开关</p><p>d.自动连接</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-03 120431.png)</p><p>e.自动识别板子型号，下载程序</p><p>f.上板验证</p><p>PS：断电程序丢失</p>]]></content>
      
      
      <categories>
          
          <category> FPGA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> 流程 </tag>
            
            <tag> 点亮LED </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>房价预测</title>
      <link href="/2024/05/06/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/"/>
      <url>/2024/05/06/%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="房价预测"><a href="#房价预测" class="headerlink" title="房价预测"></a>房价预测</h1><p>回归问题</p><p>步骤：</p><p>![](..&#x2F;img&#x2F;屏幕截图 2024-04-17 153123.png)</p><h2 id="简要过程"><a href="#简要过程" class="headerlink" title="简要过程"></a>简要过程</h2><h3 id="1-数据处理"><a href="#1-数据处理" class="headerlink" title="1.数据处理"></a>1.数据处理</h3><p>​数据结果处理后才能被模型调用</p><p>​数据导入、数据形状变换、数据集划分、数据归一化处理</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......</code></pre><h3 id="2-模型设计"><a href="#2-模型设计" class="headerlink" title="2.模型设计"></a>2.模型设计</h3><p>​就是定义一个类，里面的函数包括求w、b的值（暂时随机，将来通过“学习”求得）和一个forward函数（“推理”过程，就是用输入x、权重w、偏置b矩阵计算得到输出y）</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......<span class="keyword">class</span> <span class="title class_">Network</span>(<span class="title class_ inherited__">object</span>):​<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_weights</span>):<span class="comment"># 初始化w和b</span>        <span class="comment"># w为num_of_weights行、1列的数组（随机），b为一个数字（0）</span>​<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):​......​<span class="keyword">def</span> ...():​......</code></pre><h3 id="3-损失函数设计"><a href="#3-损失函数设计" class="headerlink" title="3.损失函数设计"></a><strong>3.损失函数设计</strong></h3><p>​loss函数放在network类里面，衡量 <em><strong>预测值 Z</strong></em> 跟 <em><strong>真实值 Y</strong></em> 之间的差距,越小越好</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......<span class="keyword">class</span> <span class="title class_">Network</span>(<span class="title class_ inherited__">object</span>):​<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_weights</span>):<span class="comment"># 初始化w和b</span>        <span class="comment"># w为num_of_weights行、1列的数组（随机），b为一个数字（0）</span>​......​<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):​......​<span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, z, y</span>):    ​......​<span class="keyword">def</span> ...():    ​......</code></pre><h3 id="4-训练过程"><a href="#4-训练过程" class="headerlink" title="4.训练过程"></a>4.训练过程</h3><p>​就是根据数据，求解w、b，使得loss函数尽可能小</p><p>​梯度下降法，介绍方法、计算balabala一大堆</p><p>​将计算过程写在network类里面的gradient函数里面，进行梯度计算</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......<span class="keyword">class</span> <span class="title class_">Network</span>(<span class="title class_ inherited__">object</span>):​<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_weights</span>):<span class="comment"># 初始化w和b</span>        <span class="comment"># w为num_of_weights行、1列的数组（随机），b为一个数字（0）</span>​......​<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):​......​<span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, z, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">self, x, y</span>):    ​......</code></pre><h3 id="5-梯度更新"><a href="#5-梯度更新" class="headerlink" title="5.梯度更新"></a>5.梯度更新</h3><p>​写一个update函数进行梯度更新（w和b）</p><p>​计算梯度只是入门，还要确定损失函数更小的点</p><p>​balabala一大堆介绍</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......<span class="keyword">class</span> <span class="title class_">Network</span>(<span class="title class_ inherited__">object</span>):​<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_weights</span>):<span class="comment"># 初始化w和b</span>        <span class="comment"># w为num_of_weights行、1列的数组（随机），b为一个数字（0）</span>​......​<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):​......​<span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, z, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">self, x, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, gradient_w, gradient_b, eta=<span class="number">0.01</span></span>):    <span class="comment"># eta=0.01：学习率参数，默认值为0.01，决定了每次参数更新的步长大小</span>​......</code></pre><h3 id="6-总结和循环"><a href="#6-总结和循环" class="headerlink" title="6.总结和循环"></a><strong>6.总结和循环</strong></h3><p>​train函数</p><p>​循环 【向前计算输出z，</p><p>​然后计算Loss（根据z,y）,</p><p>​然后计算梯度（根据loss和x），</p><p>​然后梯度更新】</p><p>​直到损失函数loss最小</p><p>​mini-batch</p><p>​随机梯度下降法（Stochastic Gradient Descent，SGD）</p><p>​就是数据太多了，一次训练花时间资源太多，不好，要从中抽一些出来作代表进行训练，求出参数</p><p>​修改train函数</p><p>​<strong>两个循环，经典四步</strong></p><p>​1.第一层循环，代表整个样本集合被训练遍历的次数，称为“epoch”。</p><p>​2.第二层循环，代表每次遍历时，样本集合被拆分成的多个批次，需要全部执行训练，称为“iter (iteration)”。</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......<span class="keyword">class</span> <span class="title class_">Network</span>(<span class="title class_ inherited__">object</span>):​<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_weights</span>):<span class="comment"># 初始化w和b</span>        <span class="comment"># w为num_of_weights行、1列的数组（随机），b为一个数字（0）</span>​......​<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):​......​<span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, z, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">self, x, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, gradient_w, gradient_b, eta=<span class="number">0.01</span></span>):    <span class="comment"># eta=0.01：学习率参数，默认值为0.01，决定了每次参数更新的步长大小</span>​......​<span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, training_data, num_epochs, batch_size=<span class="number">10</span>, eta=<span class="number">0.01</span></span>):    <span class="comment"># training_data：代表训练数据集，是一个二维数组，每一行代表一个训练样本，每一列代表样本的特征和标签。</span>        <span class="comment"># num_epochs：代表训练的轮数，即迭代次数。训练一个神经网络模型时，通常需要多次迭代才能使模型收敛到最优解。</span>        <span class="comment"># batch_size=10：代表每个小批量（mini-batch）的样本数量</span>​......</code></pre><h3 id="7-最后四步"><a href="#7-最后四步" class="headerlink" title="7.最后四步"></a>7.最后四步</h3><p>​在类后面获取数据、创建网络、启动训练、画出损失函数的变化趋势</p><p>​然后就可以根据输入x，运用训练求得的参数，计算输出y</p><p>​end</p><pre><code class="highlight python"><span class="keyword">def</span> <span class="title function_">load_data</span>():​......<span class="keyword">class</span> <span class="title class_">Network</span>(<span class="title class_ inherited__">object</span>):​<span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_of_weights</span>):<span class="comment"># 初始化w和b</span>        <span class="comment"># w为num_of_weights行、1列的数组（随机），b为一个数字（0）</span>​......​<span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):​......​<span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, z, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">gradient</span>(<span class="params">self, x, y</span>):    ​......​<span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self, gradient_w, gradient_b, eta=<span class="number">0.01</span></span>):    <span class="comment"># eta=0.01：学习率参数，默认值为0.01，决定了每次参数更新的步长大小</span>​......​<span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self, training_data, num_epochs, batch_size=<span class="number">10</span>, eta=<span class="number">0.01</span></span>):    <span class="comment"># training_data：代表训练数据集，是一个二维数组，每一行代表一个训练样本，每一列代表样本的特征和标签。</span>        <span class="comment"># num_epochs：代表训练的轮数，即迭代次数。训练一个神经网络模型时，通常需要多次迭代才能使模型收敛到最优解。</span>        <span class="comment"># batch_size=10：代表每个小批量（mini-batch）的样本数量</span><span class="comment">#取数据</span>train_data, test_data = load_data()<span class="comment"># 创建网络</span>net = Network(<span class="number">13</span>)<span class="comment"># 启动训练</span>losses = net.train(train_data, num_epochs=<span class="number">50</span>, batch_size=<span class="number">100</span>, eta=<span class="number">0.1</span>)<span class="comment"># 画出损失函数的变化趋势</span>plot_x = np.arange(<span class="built_in">len</span>(losses))plot_y = np.array(losses)plt.plot(plot_x, plot_y)plt.show()</code></pre>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 房价预测 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>大创课题</title>
      <link href="/2024/05/05/%E5%A4%A7%E5%88%9B%E8%AF%BE%E9%A2%98/"/>
      <url>/2024/05/05/%E5%A4%A7%E5%88%9B%E8%AF%BE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="大创课题"><a href="#大创课题" class="headerlink" title="大创课题"></a>大创课题</h1><h3 id="基于轻量级神经网络的无线通信调制识别及"><a href="#基于轻量级神经网络的无线通信调制识别及" class="headerlink" title="基于轻量级神经网络的无线通信调制识别及"></a><strong>基于轻量级神经网络的无线通信调制识别及</strong></h3><h3 id="FPGA硬件加速实现"><a href="#FPGA硬件加速实现" class="headerlink" title="FPGA硬件加速实现"></a><strong>FPGA硬件加速实现</strong></h3><h2 id="Q1-如何基于神经网络对无线通信的调制方式进行识别？"><a href="#Q1-如何基于神经网络对无线通信的调制方式进行识别？" class="headerlink" title="Q1:如何基于神经网络对无线通信的调制方式进行识别？"></a>Q1:<strong>如何基于神经网络对无线通信的调制方式进行识别？</strong></h2><ol><li><p><strong>数据收集</strong>：首先，需要收集不同调制方式的数据样本。这些样本可以是模拟信号，也可以是数字信号。对于数字信号，可以通过模拟调制器将数字信号调制成模拟信号，然后进行采样和记录。</p><pre><code class="highlight plaintext">调幅调制（Amplitude Modulation，AM）：单边带调幅（Single Sideband Modulation，SSB）：将频谱中的一个侧带去除，只保留正频率或负频率的一个侧带。载波抑制调幅（Carrier Suppression Amplitude Modulation，CSAM）：将载波完全去除，只保留侧带信号。调频调制（Frequency Modulation，FM）：宽带FM（Wideband FM，WBFM）：调制指数较大，频谱较宽。窄带FM（Narrowband FM，NBFM）：调制指数较小，频谱较窄。调相调制（Phase Modulation，PM）：二进制相移键控（Binary Phase Shift Keying，BPSK）：每个符号代表一个特定的相位。四进制相移键控（Quadrature Phase Shift Keying，QPSK）：每个符号代表四种不同的相位。八进制相移键控（Octal Phase Shift Keying，8PSK）：每个符号代表八种不同的相位。混合调制：混合调幅调制（Amplitude and Phase Modulation，APM）：同时对载波的幅度和相位进行调制。混合调频调制（Frequency and Phase Modulation，FPM）：同时对载波的频率和相位进行调制。正交振幅调制（Quadrature Amplitude Modulation，QAM）：16-QAM、64-QAM、256-QAM 等：通过改变振幅和相位来表示多个比特。连续相位调制（Continuous Phase Modulation，CPM）：GMSK（Gaussian Minimum Shift Keying）：使用高斯滤波器对相位进行调制，常用于GSM等系统。正交频分复用（Orthogonal Frequency Division Multiplexing，OFDM）：QAM-OFDM：将QAM调制和OFDM技术结合，常用于Wi-Fi和LTE等无线通信标准。多载波调制（Multi-Carrier Modulation，MCM）：COCOMO（Coherent Continuous Multi-carrier Modulation）：一种多载波调制技术。直接序列扩频调制（Direct Sequence Spread Spectrum Modulation，DSSS）：通过扩展码对数据进行调制，常用于CDMA系统。正交频率分复用（Orthogonal Frequency Division Multiple Access，OFDMA）：多用户接入的OFDM技术。</code></pre></li><li><p><strong>数据预处理</strong>：对于收集到的数据进行预处理，包括去噪、均衡和归一化等步骤，以确保输入数据的质量和一致性。这可以帮助提高神经网络的训练效果。</p><ul><li>Python 中的 NumPy、Pandas 和 Scikit-learn 库用于数据处理和清洗。</li><li>如果需要对信号进行频域分析，可以使用 SciPy 中的 FFT 函数。</li><li>数据可视化工具如 Matplotlib 或 Seaborn 可以帮助你理解数据的分布和特征。</li></ul></li><li><p><strong>数据标记</strong>：对每个样本进行标记，即指明它们所代表的调制方式。这是监督学习任务的一部分，需要人工标记或者利用已知的调制方式进行自动标记。</p><ul><li>如果数据集不是自动标记的，你可能需要使用标记工具（如 LabelImg）或者编写脚本来手动标记数据。</li></ul></li><li><p><strong>神经网络设计</strong>：选择适当的神经网络架构来处理调制识别任务。常用的神经网络包括卷积神经网络（CNN）、循环神经网络（RNN）和深度神经网络（DNN）。通常，对于调制识别任务，CNN是一个常见的选择，因为它能够有效地处理时域和频域上的特征。</p><ul><li>PyTorch、TensorFlow 或者 Keras 等深度学习框架用于搭建神经网络模型。</li><li>PyCharm 或者其他集成开发环境（IDE）用于编写和调试代码。</li></ul></li><li><p><strong>数据划分</strong>：将数据集划分为训练集、验证集和测试集。训练集用于训练神经网络，验证集用于调整模型参数和防止过拟合，测试集用于评估模型的性能。</p><ul><li>Scikit-learn 中的 train_test_split 函数用于将数据集划分为训练集、验证集和测试集。</li></ul></li><li><p><strong>模型训练</strong>：使用训练集对神经网络进行训练。通过反向传播算法和优化器来最小化模型预测与真实标签之间的差距（损失函数）。</p><ul><li>使用 PyTorch、TensorFlow 或者 Keras 训练神经网络模型。</li><li>在 PyCharm 中编写训练代码，并利用 GPU 加速训练（如果有的话）。</li></ul></li><li><p><strong>模型评估</strong>：使用验证集评估训练的模型性能，调整超参数和模型架构以提高性能。</p><ul><li>使用验证集评估模型的性能，可以使用 Scikit-learn 中的各种评估指标函数来评估模型的准确率、精确率、召回率等指标。</li></ul></li><li><p><strong>模型测试</strong>：使用测试集评估模型的泛化能力和准确率。这个步骤很重要，因为它反映了模型在实际应用中的表现。</p><ul><li>使用测试集评估模型在未见过的数据上的性能。</li></ul></li><li><p><strong>模型部署</strong>：当模型通过测试并且表现良好时，可以将其部署到实际系统中进行调制方式识别。</p><ul><li>可以将训练好的模型部署到实际系统中，用于调制方式的识别。具体的部署方式可能会根据实际情况有所不同，可以选择将模型封装为 API 或者嵌入到其他应用程序中。</li></ul></li></ol><h2 id="Q2-FPGA如何进行移植和部署"><a href="#Q2-FPGA如何进行移植和部署" class="headerlink" title="Q2:FPGA如何进行移植和部署"></a><strong>Q2:FPGA如何进行移植和部署</strong></h2><ol><li><strong>模型优化</strong>： 在将模型部署到 FPGA 上之前，需要对模型进行优化，以适应 FPGA 的架构和资源限制。这可能包括量化权重和激活、剪枝、模型量化、结构化剪枝等技术，以减少模型的大小和计算量，同时保持推理精度。</li><li><strong>模型转换</strong>： 将训练好的神经网络模型转换为 FPGA 可以理解和执行的格式。这可能涉及到将模型转换为 FPGA 加速器支持的特定格式，如 Xilinx 的 DNNC 或者 Intel 的 OpenVINO Model Optimizer 支持的格式。</li><li><strong>硬件描述</strong>： 编写硬件描述语言（HDL）代码，描述神经网络模型的结构和操作，以适应 FPGA 的硬件架构。这可能需要针对特定的 FPGA 平台进行优化，以最大程度地利用 FPGA 的计算资源。</li><li><strong>部署到 FPGA</strong>： 使用 FPGA 开发工具，如 Vivado（对于 Xilinx FPGA）或者 Quartus Prime（对于 Intel FPGA），将硬件描述代码综合成 FPGA 可以加载和执行的位流（bitstream）。这一步通常涉及综合、布局和布线等过程，以生成最终的可加载到 FPGA 上的二进制文件。</li><li><strong>集成和测试</strong>： 将生成的位流加载到 FPGA 开发板上，并集成到整个系统中进行测试和验证。在测试过程中，你需要确保神经网络模型能够正确地在 FPGA 上执行推理过程，并且输出结果与预期一致。</li><li><strong>性能优化</strong>： 进行性能优化，包括调整 FPGA 的时钟频率、资源分配、并行度等参数，以进一步提高推理速度和效率。这可能需要进行多次迭代和调试，以找到最佳的配置。</li><li><strong>集成到系统中</strong>： 一旦验证了 FPGA 上的推理功能，就可以将 FPGA 加速器集成到实际系统中，用于实时推理应用。这可能涉及到与系统其他组件的通信和接口设计，以确保 FPGA 加速器能够正确地与系统其他部分交互。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 未分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FPGA </tag>
            
            <tag> 大创 </tag>
            
            <tag> 深度学习 </tag>
            
            <tag> 调制方式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一些计划碎碎念</title>
      <link href="/2024/04/25/%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92%E7%A2%8E%E7%A2%8E%E5%BF%B5/"/>
      <url>/2024/04/25/%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92%E7%A2%8E%E7%A2%8E%E5%BF%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="一些计划碎碎念"><a href="#一些计划碎碎念" class="headerlink" title="一些计划碎碎念"></a>一些计划碎碎念</h1><p>找实习的时候，发现好多岗位都是计算机的，各种编程、算法、研发，好多想去但苦于自己没有技术</p><p>感觉自己大学学了个啥</p><p>啥都没有学</p><p>简历上写的到时挺高级的</p><p>面试的时候应该会一问三不知</p><p>哈哈哈哈哈哈这个世界就是一个巨大的草台班子（希望如此）</p><p>给我想笑了，看看简历上写的</p><p><img src="/../img/image-20240425220904729.png"></p><p>还有深度学习，神经网络，FPGA开发，不如再加个嵌入式吧</p><p>我能不能瞬间拥有这些能力哈哈哈哈哈哈呜呜呜呜呜呜</p><p>先说编程语言吧，Python在学深度学习的时候应该会学得差不多了</p><p>c++还得另外学，不然再学个Java吧，</p><p>哎我突然想到一个学习计划</p><blockquote><p>先在csdn上看一下，总结一下基础知识，在md上</p><p>然后再多看几个例子，每个都详细看一下，敲一下代码</p><p>再自己做几个题目</p><p>最后看看有没有必要去刷一下力扣的题目，我觉得就差不多了</p></blockquote><p>接下来就是专业知识</p><p>我觉得最重要的是</p><ul><li>信号与系统</li><li>通信原理</li><li>数字电子技术</li><li>模拟电子技术</li></ul><p>其次是</p><ul><li>电路分析原理</li><li>电磁场与电磁波（电动力学）</li><li>单片机</li><li>计算机组成原理</li><li>eda</li><li>网络技术</li></ul><p>其他的准备一下本学期的内容吧</p><ul><li>高频电子技术</li><li>计算机接口技术</li></ul><p>专业课我觉得基本就是这些了</p><p>我作为一个有能力的人，要有自己的壁垒，是别人没有的，这样手握一门技术（dream一个全栈）</p><p>这里要科普一下全栈</p><blockquote><p>​全栈工程师是既能开发客户端应用程序，又能开发服务器端应用程序，甚至还需要做产品搞设计的一群人，他们具备解决软件开发过程中各个层面的各种问题的能力。</p><p>​<strong>说白了就是，全栈工程师就是啥都得干，啥都得会干。</strong></p></blockquote><p><img src="/../img/v2-16a598797e7b6db45048af0896ffaf7b_1440w.jpg"></p><p><img src="C:\Users\mymdy\AppData\Roaming\Typora\typora-user-images\image-20240425222929796.png" alt="image-20240425222929796"></p><p><strong>总结一下</strong>：</p><hr><p>专业课的知识↑</p><p>​这是很重要的，我要开始洗脑我已经掌握了好多了，再看看视频、看看书就能掌握</p><p>​然后考研相关的还要多刷题</p><hr><p>编程能力：c++、Python、Java</p><hr><p>外语能力：口语、阅读、应试</p><hr><p>高等数学、线性代数、概率论与数理统计</p><hr><p>政治</p><hr><p>应该没有遗漏的了吧……</p><p>​                                                  <em><strong>分割一下：2024.04.25  22:41</strong></em></p><hr><hr><hr><hr><hr><hr><p>以速成课逐个攻克</p><p>以半个月为周期</p><p>5.1-5.15：</p><p>通信原理、高频电子技术、计算机接口技术、高等数学1-8讲</p><p>贯穿其中：深度学习、FPGA</p>]]></content>
      
      
      <categories>
          
          <category> 未分类 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计划 </tag>
            
            <tag> 专业 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
